# 5-Day AI Agents Course with Google and Kaggle - Self Paced AI Agents Course

Trata-se de um evento criado pela Google e que foi disponibilizado ao p√∫blico geral como trilha de aprendizado **Self-Paced** para a **constru√ß√£o e a implanta√ß√£o de Agentes de IA**.


Este curso foi iniciado e terminado em **DEZ-2025**, e ele inclu o acesso a documentos t√©cnicos da Google, Podcasts e Livestreams gravadas, juntamente com o trabalho de gerenciamento de recursos de aprendizado pela Kaggle, atrav√©s de seus Notebooks devidamente preparados.


A trilha [5-Day AI Agents Intensive Course with Google](https://www.kaggle.com/learn-guide/5-day-agents?utm_medium=email&utm_source=gamma&utm_campaign=learn-aiagents-2025) traz como ensinamentos:

- Introduction to Agents
- Agent Tools & Interoperability with MCP
- Context Engineering: Sessions & Memory
- Agent Quality
- Prototype to Production


<br>

## Primeiro Dia de Pr√°tica - 5-Day AI Agents Intensive Course with Google

Abaixo temos um resumo do pricipal que fora visto nos cinco dias de aprendizado com agentes de IA na trilha [5-Day AI Agents Intensive Course with Google](https://www.kaggle.com/learn-guide/5-day-agents?utm_medium=email&utm_source=gamma&utm_campaign=learn-aiagents-2025) que fora disponibilizado pela plataforma Kaggle.


<br>

### Pr√°tica I

Neste primeiro dia de pr√°tica, √© apresentada a base sobre a tecnologia e o uso pr√°tico dos agentes de IA, sendo que a pr√≥pria Google disponibilizou uma biblioteca que traz recursos e depend√™ncias necess√°rias para facilitar a cria√ß√£o e a opera√ß√£o de agentes para diversas linguagens, entre elas, para o Python: **google-adk**

```
pip install google-adk
```

Esta biblioteca agn√≥stica da Google, usada para facilitar o trabalho de constru√ß√£o de agentes de IA com diversos modelos, possui estes 3 principais componentes:

1. **Agente**: defini configura√ß√µes para o bot como: personalidade, miss√£o, modelo de IA utilizado e autoriza√ß√£o de acesso √† ferramentas.
2. **Session**: usado para armazenar o hist√≥rico das intera√ß√µes
3. **Runner**: gerencia a engine para executar a tarefa.


A seguir n√≥s instalamos a biblioteca **os** e adicionamos a chave da GOOGLE_API_KEY:

```
import os
from kaggle_secrects import UserSecretsClient

try:
    GOOGLE_API_KEY = UserSecretsClient().get_secret("5day-agents-kaggle")
    os environ["5day-agents-kaggle"] = GOOGLE_API_KEY
    print("Gemini API key setup complete.")
 except Exception as e:
    print(
        f"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}"
)
```


Depois s√£o importados os componentes da biblioteca **google-adk**:

```
from google.adk.agents import Agent
from google.adk.models.google_llm import Gemini
from google.adk.runners import InMemoryRunner
from google.adk.tools import google_search
from google.genai import types

print("‚úÖ ADK components imported successfully.")
```


Depois, √© necess√°rio criar algumas configura√ß√µes particulares para gerenciar **Retry Options**, ou seja, elementos que permitam o agente a lidar como algumas falhas potenciais do modelo, como exaust√£o de tokens ou indisponibilidade de internet, etc.


Assim, dessa forma o agente pode se valer de funcionalidades para automaticamente realizar novas tentativas de opera√ß√£o:

```
retry_config=type.HttpRetryOptions(
        attempts=5,
        exp_base=7          #Rdelay multiplier
        initial_delay=1     # Initial delay before retry (in sec)
        http_status_codes=[429, 500, 503, 504]
)
```


Na sequ√™ncia, √© preciso descrever a funcionalidade do agente de IA, que neste caso √© o de fazer consultas na ferramenta do Googl Search. E para come√ßar a configura√ß√£o escolhemos um nome, o modelo da IA, etc.:

```
root_agent = Agent(
        name="helpful_assistant",
        model=Gemini(
            model="gemini-2.5.flash-lite",
            retry_options=retry_config
        ),
        description="A simple agent that can answer genral questions.",
        instruction="You are a helpful assistant. Use Google Search for current info or if unsure."
        tools=[google_search],
)

```


Finalmente, executamos o agente chamando um orquestrador ou um **runner** para gerenciar sua opera√ß√£o, bem como chamamos um debugador de auditoria ou de manuten√ß√£o para que possamos acompanhar tamb√©m os passos realizados pelo agente na realiza√ß√£o de sua tarefa b√°sica que √© **realizar uma pesquisa no Google Search**:

```
runner = InMemoryRunner(agent=root_agent)
print("‚úÖ Runner created.")

response = await runner.run_debug(
    "What is Agent Development Kit from Google? What languages is the SDK available in?"
)
```


E vemos, no script acima, que o agente √© definido para ser executado numa fun√ß√£o em mem√≥ria RAM. 


<br>

### Pr√°tica II

Depois de ter sido criado um agente singular para a realiza√ß√£o de uma simples atividade na **Pr√°tica I**, agora a tarefa √© escalada para a constru√ß√£o de um time de agentes de IA.


A ideia aqui √© de escalar a opera√ß√£o evitando gerar muita complexidade, de modo que ent√£o, ao inv√©s de se criar agentes abarrotados de responsabilidades, s√£o criados v√°rios agentes simples individualizados para que em conjunto um problema maior e mais complexo possa ser resolvido. 


E isso seria dado o nome de **multi-agent system**, sendo que esse conceito seria dos mais importantes na opera√ß√£o de desenvolvimento de agenstes de IA.


Outro ponto a se observar nesta segunda pr√°tica, √© o fato de haver tr√™s modelos de workflow para coordenar a colabora√ß√£o entre os agentes:

1. **Sequencial**
2. **Paralela**
3. **Em loop**

![multi-agent-team-system](./public/multi-agent-team-system.png)


<br>

Segundo a documenta√ß√£o do Google, v√°rias seriam as vantagens de se escalar a opera√ß√£o atrav√©s de cria√ß√£o de v√°rios agentes simples especializados para trabalharem em colabora√ß√£o:

- √â mais f√°cil debugar individualmente cada agente, do que .a manuten√ß√£o de um grande e complicado super agente
- √â mais f√°cil para testar individualmente cada agente, do que a manuten√ß√£o de um grande e complicado super agente.
- √â mais f√°cil para fazer a manuten√ß√£o individual de um simples agente, do que a manuten√ß√£o de um grande e complicado super agente.


<br>

Assim, novamente ao come√ßar essa nova pr√°tica √© preciso lembrar que em nossa **Pr√°tica I**, n√≥s j√° realizamos a instala√ß√£o das depend√™ncias necess√°rias para o uso da biblioteca **google-adk**, bem como discutimos tamb√©m a necessidade de se fazer o gerenciamento da chave de API para as aplica√ß√µes da Google:

```
pip install google-adk
```


E,

```
import os
from kaggle_secrets import UserSecretClient

try:
    GOOGLE_API_KEY = UserSecretClient().get_secret("5day-agents-kaggle")
    os.environ["5day-agents-kaggle"] = GOOGLE_API_KEY
    print("‚úÖ Gemini API key setup complete.")
except Exception as e:
    print(
        f"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}"
)
```


A seguir, podemos observar agora diferen√ßas com rela√ß√£o √† importa√ß√£o de novas funcionalidade em rela√ß√£o √† pr√°tica anterior, pois vmos abaixo a chamada dos tr√™s tipos de modelos de gest√£o do time de agentes, bem como temos mais duas novas ferramentas sendo importadas: **AgentTool** e **FuncitonTool**.

```
from google.adk.agnts import Agent, SequentialAgent, ParallelAgent, LoopAgent
from google.adk.models.google_llm import Gemini
from google.adk.runners import InMemoryRunner
from google.adk.tools import AgentTool, FuncionToll, google_search

print("‚úÖ ADK components imported successfully.")
```


Finalmente, para finalizar a prepara√ß√£o do ambiente de opera√ß√£o dos agentes √© preciso configurar tamb√©m as op√ß√µes para automatizar as novas tentativas de acesso √† LLM, como fora feito ateriormente:

```
retry_config=types.HttpRetryOptions(
    attempts=5,
    exp_base=7,         # Delay multiplier
    initial_delay=1, 
    http_status_codes=[429, 500, 503, 504],
)
```


Observe, ent√£o, que para a constru√ß√£o do time de agentes, s√£o criados primeiramente dois agentes para trabalhar as tarefas e um agente de coordena√ß√£o, que como pode ser visto no c√≥digo chama cada agente como se fossem ferramentas em geral:

```
# Agent I - Research Agent: job to research at google_search
research_agent = Agent(
    name="ResearchAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""You are a specialized research agent. Your only job is to use the
    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.""",
    tools=[google_search],
    output_key="research_findings", # The result of this agent will be stored in the session state with this key.
)

print("‚úÖ research_agent created.")

# Agent II - Summarizer Agent: job to summarize the text received
summarizer_agent = Agent(
    name="SummarizerAgent",
    model=Gemini(
        model="gemini-2.5-flash-lie",
        retry_options=retry_config
    ),
    instructition="""Read the provided research findings: {research_findings}
Create a concise summary as a bulleted list with 3-5 key points.""",
    output_key="final_summary",
)

print("‚úÖ summarizer_agent created.")

# Agent III - Root-Coordinator: job to orquestrate the flow by calling the sub-agents as tools
root_agent = Agent(
    name="ResearchCoordinator",
    model=Gemini(
    model="gemini-2.5-flash-lite",
    retry_options=retry_config
    ),
    instruction="""You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.
1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.
2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.
3. Finally, present the final summary clearly to the user as your response.""",
    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],
)

print("‚úÖ root_agent created.")
```


Finalmente, executamos o agente chamando um orquestrador ou um **runner** para gerenciar sua opera√ß√£o, bem como chamamos um debugador de auditoria ou de manuten√ß√£o para que possamos acompanhar tamb√©m os passos realizados pelo agente na realiza√ß√£o de sua tarefa b√°sica que √© **realizar uma pesquisa no Google Search**:

```
runner = InMemoryRunner(agent=root_agent)
response = await runner.run_debug(
    "What are the latest advancements in quantum computing and what do they mean for AI?"
)
```

> [!NOTE]
> Observe que pelo modelo de orquestra√ß√£o utilizado acima com o **root_agent** temos um controle definido no pr√≥prio prompt do agente de base que busca delinear o seu comportamento.
> Contudo, segundo os documentos t√©cnicos do Google, essa forma de utiliza√ß√£o da orquestra√ß√£o √© prec√°ria, porque depende apenas do modelo de IA para garantir a realiza√ß√£o da sequ√™ncia correta das tarefas, sem possuir qualquer garantia para o caso do modelo n√£o conseguir os passos definidos!!!


<br>

√â assim, ent√£o, que entra em cena o uso do recurso da cria√ß√£o de uma pipeline, por meio da fun√ß√£o **SequentialAgent**, que vai definir e controlar todo o comportamento do **root_agent**:

```
root_agent = SequentialAgent(
    name="SearchPipeline",
    sub_agents=[research_agent, summarizer_agent],
)

print("‚úÖ Sequential Agent created.")

runner = InMemoryRunner(agent=root_agent)
response = await runner.run_debug(
    "What are the latest advancements in quantum computing and what do they mean for AI?"
)
```


Assim, considerando que neste caso apresentado temos uma orquestra√ß√£o que depende de tarefas sendo realizadas uma ap√≥s a outra e queo resultado de cada uma delas √© repassado para o pr√≥ximo agente para ser atualizado por ele, uma pipeline de tarefas sequenciais faz todo o sentido.


Contudo, em muitos casos, as tarefas podem apresentar conforma√ß√µes diversificadas, como, por exemplo, de tarefas independentes uma das outras ou de tarefas que precisam ser feitas reiteradamente, de forma que para esses casos caberia o uso de objetos diferentes para controlar a pipleline:

- **ParallelAgent**
- **LoopAgent**


Observe, ainda, que a forma de chamar essas pipelines √© um pouco mais complexa do que a maneira de lidar com o problema b√°sico de uma pipeline sequencial.


Isto porque, em ambos os casos acima, existe a necessidade de se utilizar um agente especializado para agrupar a pipeline, enquanto que o **root_agent** fica respons√°vel apenas por fazer a chamada inicial da orquestra√ß√£o e manter o seu controle geral.


Assim, em um poss√≠vel exemplo de agentes trabalhando paralelamente, ter√≠amos tantos quantos agentes realizando suas tarefas independentes sendo agrupados em um **parallel_agent**, enquanto que o **root_agent** controla a orquestra√ß√£o como um todo, como vemos abaixo:

```
# parallel_research runs every agent simultaneously
parallel_research_tea = ParallelAgent(
    name="ParallelResearchTeam",
    sub_agents=[tech_reasearcher, health_researcher, finance_researcher],
)

# root_agent runs both the agent team and another agent that works sequentially
root_agent = SequentialAgent(
    name="ReserachSystem",
    sub_agents=[parallel_research_team, aggregator_agent,
)

print("‚úÖ Parallel and Sequential Agents created.")
```


Do outro lado, pensando em um exemplo para se aproveitar da possibilidade da chamada reiterada de tarefas em loop, tamb√©m √© usado um agente que agrega todos os agentes trabalhando em loop, enquanto que novamente, o **root_agent** fica responsabilizado por fazer a chamada inicial dos agentes principais e por controlar a orquestra√ß√£o da opera√ß√£o como um todo:

```
# LoopAgent contains two agents working in loop and also a explicit clause to avoid infinite loops
story_refinement_loop = LoopAgent(
    name="StoryRefinementLoop",
    sub_agents=[critic_agent, refiner_agent],
    max_iterations=2 # Prevents infinite loops
)

# root_agent runs both the LoopAgent and the initial_writer_agent
root_agent = SequentialAgent(
    name="StoryPipeline",
    sub_agents=[initial_writer_agent, story_refinement_loop],
)

print("‚úÖ Loop and Sequential Agents created.")
``` 


> [!NOTE]
> Observe que para controlar as itera√ß√µes de loop das tarefas, n√£o apenas o Loop_Agent tem uma cl√°usula expl√≠cita para finalizar loops e evitar erros internos dos modelos dos agentes que levassem a loop infinitos, mas que entre o grupo de agentes que realiza as tarefas em loop, um deles carrega consigo a responsabilidade de fazer a chamada de uma fun√ß√£o para a sa√≠da natural do loop, isto √©, com a finaliza√ß√£o normal das tarefas e sem precisar da aplica√ß√£o da cl√°usula de preven√ß√£o de loops infinitos presentes no Loop_Agent. 


<br>

## Segundo Dia de Pr√°tica - 5-Day AI Agents Intensive Course with Google

- [5-Day AI Agents Intensive Course with Google](https://www.kaggle.com/learn-guide/5-day-agents?utm_medium=email&utm_source=gamma&utm_campaign=learn-aiagents-2025)


<br>

### Pr√°tica I

Neste segundo dia de pr√°tica, o foco passa a ser as ferramentas ou **tools** que s√£o apresentadas aos agentes para que estes pudessem ir al√©m da constru√ß√£o de tarefas textuais, que √© a tarefa b√°sica e que define o seu trabalho como uma MML, ou seja, da possibilidade de responder a um ponto ou quest√£o espec√≠fica para um usu√°rio, para, ent√£o, poderem ir al√©m e come√ßarem a atuar diretamente no mundo circundante utilizando-se de ferramentas para este intento.


Assim, como tinha sido definido anteriormente nos documentos da Google para essa trilha, as ferramentas seriam as m√£oes e os bra√ßos com as quais os agentes poderiam sair do limite de opera√ß√£o dos seus prompts para realizar tarefas completas, permitindo os modelos conhecerem coisas para al√©m daquilo que foram treinadas ou para realizar tarefas espec√≠ficas.

![agentes-delegando-tarefas-para-ferramentas](./public/agentes-delegando-tarefas-para-ferramentas.png)


<br>

Observe ainda que esse direcionamento dos prompts para a a√ß√£o n√£o ocorreu sem os seus percalsos, de forma que aqui √© importante a aplica√ß√£o de modelos e melhores pr√°ticas comprovadas para evitar a cria√ß√£o de complexas e intrincadas opera√ß√µes que depois s√£o virtualmente imposs√≠veis de serem mantidas ou escaladas.


Nesse sentido surge o **MCP** ou **Model Context Protocol**, e que foi inspirado da linguagem de protocolos de servi√ßo LSP, que segue a arquitetura Cliente-Servidor. Nesses termos, a arquitetura desse protocolo trabalha com tr√™s componentes principais que se comunica atrav√©s de JSON (RCP 2.0), que trazem campos como **name** e **description**:

1. **MCP Host**: seria a aplica√ß√£o orquestrando os clientes MCP.
2. **MCP Client**: trata-se do software que realiza os pedidos de conex√£o √† ferramenta e recebe as respostas.
3. **MCP Server**: um servidor que anuncia ferramentas dispon√≠veis.


Assim, em um servidor MCP, um exemplo de schema JSON poderia ser:

![tool-definition-json-em-serividores-mcp](./public/tool-definition-json-em-serividores-mcp.png)


<br>

Assim, nesta primeira tarefa do segundo dia da trilha busca expandir √†s capacidades do que os agentes poderiam fazer nas opera√ß√µes de relacionadas a "IA Agente"!


Nesse sentido, como dito antes, a capacidade de extensibilidade por parte dos agentes de IA √© feita pelo uso de ferramentas, que no caso desta pr√°tica envolvem **a constru√ß√£o de fun√ß√µes customizadas**, uma vez que nos exemplos do primeiro dia j√° foram utilizadas ferramentas da API da Google, como o Google Search, por exemplo. 


E, tal qual √†s tarefas feitas no primeiro dia, o trabalho de prepara√ß√£o do projeto se inicia com a configura√ß√£o b√°sica do ambiente local e com a gest√£o da chave de autentica√ß√£o para a Api Gemini, de modo que os c√≥digos s√£o repetidos e podem ser revisados nas duas tarefas do primeiro dia de pr√°tica da trilha.


Assim, podemos ver novas adi√ß√µes ao trabalho ao observar a parte de importa√ß√µes das bibliotecas Python: 

```
from google.genai import types

from google.adk.agents import LlmAgent
from google.adk.models.google_llm import Gemini
from google.adk.runners import InMemoryRunner
from google.adk.sessions import InMemorySessionService
from google.adk.tools import google_search, AgentTool, ToolContext
from goolge.adk.code_executors import BuiltInCodeExecutor 

print("‚úÖ ADK components imported successfully.")
```


No c√≥digo acima, duas grandes diferen√ßas que aparecem agora s√£o a importa√ß√£o do gerenciamento de sess√µes e do construtor de c√≥digo executor, sendo que a seguir o exemplo traz uma fun√ß√£o auxiliar para justamente fazer a impress√£o do c√≥digo:

```
def show_python_code_and_result(response):
    for i in range(len(response)):
        # Check if the response contains a valid function call result from the code executor
        if (
            (response[i].content.parts)
            and (response[i].content.parts[0])
            and (response[i].content.parts[0].function_response)
            and (response[i].content.parts[0].function_response.response)
        ):
            response_code = response[i].content.parts[0].function_response.response
            if "result" in response_code and response_code["result"] != "```":
                if "tool_code" in response_code["result"]:
                    print(
                        "Generated Python Code >> ",
                        response_code["result"].replace("tool_code", ""),
                    )
                else:
                    print("Generated Python Response >> ", response_code["result"])


print("‚úÖ Helper functions defined.")
```


A seguir, tal fora visto nas duas tarefas do dia primeiro, √© feito um objeto de configur√ß√£o para lidar com **"transient errors"** especificamente pelas chamadas feitas pelo modelo LLM, configura√ß√£o, que como se v√™ no primeiro dia, cria uma limita√ß√µes de tentativas e gera um delay de base entre as tentativas refeitas, etc.


Na continua√ß√£o, o agente passa a dispor das fun√ß√µes que descrevem as ferramentas para seu uso, sendo importante observar que segundo √†s diretrizes do curso, para o Python, significa simplesmente fazer:

1. **Cria√ß√£o da fun√ß√£o Python**
2. **Aplica√ß√£o das boas pr√°ticas**
3. **Adi√ß√£o da fun√ß√£o que descreve a ferrameta (tool) na lista de ferramentas de uso do agente de IA**

![diretrizes-para-criacao-de-ferramentas-customizadas-para-agentes-de-ia](./public/diretrizes-para-criacao-de-ferramentas-customizadas-para-agentes-de-ia.png)


<br>

```
# Pay attention to the docstring, type hints, and return value.
def get_fee_for_payment_method(method: str) -> dict:
    """Looks up the transaction fee percentage for a given payment method.

    This tool simulates looking up a company's internal fee structure based on
    the name of the payment method provided by the user.

    Args:
        method: The name of the payment method. It should be descriptive,
                e.g., "platinum credit card" or "bank transfer".

    Returns:
        Dictionary with status and fee information.
        Success: {"status": "success", "fee_percentage": 0.02}
        Error: {"status": "error", "error_message": "Payment method not found"}
    """
# This simulates looking up a company's internal fee structure
    fee_database = {
        "platinum credit card": 0.02, # 2%
        "gold debit card": 0.035, # 3.5%
        "bank transfer": 0.01, # 1%
    }

    fee = fee_database.get(method.lower())

    if fee is not None:
        return {"status": "success", "fee_percentage": fee}
    else:
        return{
            "status": "error",
            "error_message": f"Payment method '{method}' not found".
        }

print("‚úÖ Fee lookup function created")
```


J√° a segunda fun√ß√£o/tool customizada seria:

```
def get_exchange_rate(base_currancy: str, target_currency: str) -> dict:
    """Looks up and returns the exchange rate between two currencies.

    Args:
        base_currency: The ISO 4217 currency code of the currency you
                       are converting from (e.g., "USD").
        target_currency: The ISO 4217 currency code of the currency you
                         are converting to (e.g., "EUR").

    Returns:
        Dictionary with status and rate information.
        Success: {"status": "success", "rate": 0.93}
        Error: {"status": "error", "error_message": "Unsupported currency pair"}
    """

    # Static data simulating a live exchange rate API
    # In production, this would call something like: requests.get("api.exchangerates.com")
    rate_database: = {
        "usd": {
            "eur": 0.93,  # Euro
            "jpy": 157.50,  # Japanese Yen
            "inr": 83.58,  # Indian Rupee        
        }
    }

    # Input validation and processing
    base = base_currency.lower()
    target = target)currency.lower()

    # Return structured result with status
    rate = rate_database.get(base, {}).get(target)
    if rate is not None:
        return {"status": "success", "rate": rate}
    else:
        return {
            "status": "error",
            "error_message": f"Unsupported currency pair: {base_currency}/{target_currency}",
        }

print("‚úÖ Exchange rate function created")
print(f"üí± Test: {get_exchange_rate('USD', 'EUR')}")
```


Assim vemos nos c√≥digos acima a assinatura de declara√ß√£o das fun√ß√µes a serem usadas como ferramentas customizadas pelo agente de IA j√° trazendo os pontos de boas pr√°ticas que foram anteriomente definidos:

1. **Dictionary returns**
2. **Clear docstrings**
3. **Type hints**
4. **Error handling**


Na sequ√™ncia temos a cria√ß√£o do agente de IA, que como importante fun√ß√£o, deve terna sua lista de tarefas o nome exato das fun√ß√µes customizadas:

```
# Currency agent with custom function tools
currency_agent = LlmAgent(
    name="currency_agent",
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    instruction="""You are a smart currency conversion assistant.

    For currency conversion requests:
    1. Use `get_fee_for_payment_method()` to find transaction fees
    2. Use `get_exchange_rate()` to get currency conversion rates
    3. Check the "status" field in each tool's response for errors
    4. Calculate the final amount after fees based on the output from `get_fee_for_payment_method` and `get_exchange_rate` methods and provide a clear breakdown.
    5. First, state the final converted amount.
        Then, explain how you got that result by showing the intermediate amounts. Your explanation must include: the fee percentage and its
        value in the original currency, the amount remaining after the fee, and the exchange rate used for the final conversion.

    If any tool returns status "error", explain the issue to the user clearly.
    """,
    tools=[get_fee_for_payment_method, get_exchange_rate],
)

print("‚úÖ Currency agent created with custom function tools")
print("üîß Available tools:")
print("  ‚Ä¢ get_fee_for_payment_method - Looks up company fee structure")
print("  ‚Ä¢ get_exchange_rate - Gets current exchange rates")
``` 


Finalmente, como j√° de costume, chamamos o ambiente de execu√ß√£o do runner para o agente de IA, lembrando de passar tamb√©m a fun√ß√£o de debuga√ß√£o, tal qual fora bastante explicado nas pr√°ticas do primeiro dia da trilha:

```
# Test the currency agent
currency_runner = InMemoryRunner(agent=currency_agent)
_ = await currency_runner.run_debug(
    "I want to convert 500 US Dollars to Euros using my Platinum Credit Card. How much will I receive?"
)
```


Contudo, buscando trazer maior robustez √† opera√ß√£o, √© lembrado que LLms n√£o s√£o sempre confi√°veis na realiza√ß√£o de opera√ß√µes matem√°ticas, de modo que uma arquitetura melhor implicaria na constru√ß√£o do c√≥digo pelo uso do Python, que ent√£o usaria o recurso integrado da biblioteca **google-adk** para a constru√ß√£o de c√≥digo, como fora feita a importa√ß√£o ao come√ßo da pr√°tica.

![enhanced-currency-agent-que-chama-um-agente-como-ferramenta-de-calculo](./public/enhanced-currency-agent-que-chama-um-agente-como-ferramenta-de-calculo.png)

<br>

Assim, o c√≥digo √© constru√≠do por um segundo agente de IA, este que ent√£o faz a chaamada para a constru√ß√£o do c√≥digo Python para  realizar o c√°lculo matem√°tico:

```
calculation.agent = LlmAgent(
    name="CalculationAgent",
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    instruction="""You are a specialized calculator that ONLY responds with Python code. You are forbidden from providing any text, explanations, or conversational responses.
 
     Your task is to take a request for a calculation and translate it into a single block of Python code that calculates the answer.
     
     **RULES:**
    1.  Your output MUST be ONLY a Python code block.
    2.  Do NOT write any text before or after the code block.
    3.  The Python code MUST calculate the result.
    4.  The Python code MUST print the final result to stdout.
    5.  You are PROHIBITED from performing the calculation yourself. Your only job is to generate the code that will perform the calculation.
   
    Failure to follow these rules will result in an error.
       """
    code_executor=BuiltInCodeExecutor(), # Use the built-in Code Executor Tool. This gives the agent code execution capabilities
)
```


A seguir, precisamos atualizar o agente orquestrador, observando agora que al√©m de contralar a configura√ß√£o das fun√ß√µes customizadas utilizadas como ferramenta pela opera√ß√£o, o construtor tamb√©m controla a chamada do agente de IA auxiliar de c√°lcula, na forma de uma ferramenta tamb√©m. Ademais, ao final √© feita nova chamada ao runner:

```
enchanced_currency_agent = LlmAgent(
    name="enhanced_currency_agent",
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    # Updated instruction
    instruction="""You are a smart currency conversion assistant. You must strictly follow these steps and use the available tools.

  For any currency conversion request:

   1. Get Transaction Fee: Use the get_fee_for_payment_method() tool to determine the transaction fee.
   2. Get Exchange Rate: Use the get_exchange_rate() tool to get the currency conversion rate.
   3. Error Check: After each tool call, you must check the "status" field in the response. If the status is "error", you must stop and clearly explain the issue to the user.
   4. Calculate Final Amount (CRITICAL): You are strictly prohibited from performing any arithmetic calculations yourself. You must use the calculation_agent tool to generate Python code that calculates the final converted amount. This 
      code will use the fee information from step 1 and the exchange rate from step 2.
   5. Provide Detailed Breakdown: In your summary, you must:
       * State the final converted amount.
       * Explain how the result was calculated, including:
           * The fee percentage and the fee amount in the original currency.
           * The amount remaining after deducting the fee.
           * The exchange rate applied.
    """,
    tools=[
        get_fee_for_payment_method,
        get_exchange_rate,
        AgentTool(agent=calculation_agent), # Using another agent as a tool!
    ],
)


print("‚úÖ Enhanced currency agent created")
print("üéØ New capability: Delegates calculations to specialist agent")
print("üîß Tool types used:")
print("  ‚Ä¢ Function Tools (fees, rates)")
print("  ‚Ä¢ Agent Tool (calculation specialist)")

enhanced_runner = InMemoryRunner(agent=enhanced_currency_agent)
response = await enhanced_runner.run_debug(
    "Convert 1,250 USD to INR using a Bank Transfer. Show me the precise calculation."
)
```


Finalmente, ao finalizar esta pr√°tica, o curso explica a diferen√ßa no uso de **Agent Tools vs Sub-Agents**, de modo que:


1. **Agent Tools (Que √© o modelo usado nesta pr√°tica!!!;));**
    - Agente A chama Agente B como uma ferramenta
    - Agente B apresenta de volta sua resposta ao Agente A
    - O Agente A permanece no controle e √© respons√°vel por continuar a conversa√ß√£o
    - Caso de uso: Delega√ß√£o para tarefas espec√≠ficas (como c√°lculos)
2. **Sub-Agents (um padr√£o diferente):**
    - Agente A transfere o controle completamente para o Agente B
    - Agent B recebe a tarefa e passa a assumir todas as futuras intera√ß√µes com os imputes do usu√°rio
    - Agente A sai do loop das tarefas
    - Caso de uso: Entrega de tarefas feitas para especialistas (como os casos envolvendo agentes de suporte √† clientes, etc.)


<br>

### Tarefa II

Nesta segunda tarefa do segundo dia da trilha, que tamb√©m busca fazer a expans√£o das capacidades dos agentes de IA pelo uso de ferramentas, tamb√©m precisa, como todas as tarefaas anteriores,  fazer o trabalho de prepara√ß√£o do projeto, que se inicia com a configura√ß√£o b√°sica do ambiente local e com a gest√£o da chave de autentica√ß√£o para a Api Gemini, de modo que os c√≥digos s√£o repetidos e podem ser revisados especialmente nas tarefas do primeiro dia de pr√°tica da trilha. 


Na sequ√™ncia de prepara√ß√£o desta segunda pr√°tica, ent√£o, √© o momento de se fazer aimporta√ß√£o das bibliotecas:

```
import uuid
from google.genai import types

from google.adk.agents import LlmAgent
from google.adk.models.google_llm import Gemini
from google.adk.runners import runner
from google.adk.sessions import InMemorySessionService

from google.adk.tools.mcp_tool.mcp_toolsel import McpToolset
from google.adk.tools.tool_context import ToolContext
from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectonParams
from mcp import StdioServerParameters

from google.adk.apps.app import App, ResumabilityConfig
from google.adk.tools.functions_tool import FunctionTool

print("‚úÖ ADK components imported successfully.")
``` 


Assim, observando as linhas de importa√ß√µes acima, podemos ver que al√©m de algumas importa√ß√µes j√° conhecidas das pr√°ticas anteriores, temos uma se√ß√£o inteira para a chamada dos recursos do **MCP**, bem como podemos ver tamb√©m uma chamada relacionada a um recurso para **Apps**.

 
E a prepara√ß√£o da pr√°tica termina, novamente, com a configura√ß√£o da se√ß√£o para lidar com **"transient errors"** especificamente pelas chamadas feitas pelo modelo LLM, configura√ß√£o, que como se v√™ no primeiro dia, cria uma limita√ß√µes de tentativas e gera um delay de base entre as tentativas refeitas, etc.


Assim, como rela√ß√£o ao que temos de novo nesta pr√°tica, sobre o **MCP** ou Model Context Protocol, que √© uma:

> "Model Context Protocol (MCP) is an open standard that lets agents use community-built integrations. Instead of writing your own integrations and API clients, just connect to an existing MCP server."


Nesse sentido, temos Agentes MCP para:

- **Access live, external data from databases, APIs, and services without custom integration code**
- **Leverage community-built tools with standardized interfaces**
- **Scale capabilities by connecting to multiple specialized servers**


Tamb√©m explica o recurso de ensino da trilha que o protocolo **MCP** funciona conectando os agentes criados como usu√°rios aos servidores MCP externos, que funcionam todos padronizados de acordo com este mesmo protocolo:

![explicacao-da-arquitetura-de-funcionamento-do-protocolo-mcp](./public/explicacao-da-arquitetura-de-funcionamento-do-protocolo-mcp.png)


<br>

E assim o recurso de ensino explica que para esta pr√°tica ser√° usado o servidor MCP **Everything MCP Server** que √© um **npm package** (@modelcontextprotocol/server-everything) desenhado para testar integra√ß√µes MCP.


Aliais, o **MCP Toolset** que cria a integra√ß√£o com o MCP Server usa o pacote de execu√ß√£o do **Node-js**, o **npx** para executar o MCP Server, conectando-o a @modelcontextprotocol/server-everything e, de acordo com a imagem criada pela chamada do c√≥digo abaixo, filtrando apenas o uso do m√≥dulo **getTinyImage tool** no servidor (que no todo possui muitas outras ferramentas, mas que n√£o vem ao caso nesta pr√°tica):

```
# MCP integration with Everything Server
mcp_image_server = McpToolset(
    connection_params=StdioConnectionParams(
        server_params=StdioServerParameters(
            command="npx",  # Run MCP server via npx
            args=[
                "-y",  # Argument for npx to auto-confirm install
                "@modelcontextprotocol/server-everything",
            ],
            tool_filter=["getTinyImage"],
        ),
        timeout=30,
    )
)

print("‚úÖ MCP Tool created")
```


Finalmente, o recurso de aprendizagem explica asim o funcionamento do servidor executado por **npx -y @modelcontextprotocol/server-everything**

1. Estabelecimento de canal de comunica√ß√£o com o **stdio**
2. Descoberta de ferramentas: que o servidor vai anunciar aos recursos do **google-adk** que a funcionalidade  **getTinyImage** est√° sendo provida.
3. Integra√ß√£o de ferramentas anunciadas de forma autom√°tica.
4. Execu√ß√£o de chamadas ao MCP Server quando os agentes de IA chamam a fun√ß√£o getTinyImage().
5. Resposta retornada de forma cont√≠nua ou sem interrup√ß√µes ao agente.


Assim, adicionando o **mcp_server** ao agente, temos:

```
image_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="image_agent",
    instruction="Use the MCP Tool to generate images for user queries",
    tools=[mcp_image_server,
)
```


A seguir, criando o ambiente de execu√ß√£o, bem como o de teste e debug para o agente:

```
from google.adk.runners import InMemoryRunner
runner = InMemoryRunner(agent=image_agent)

response = await runner.run_debug("Provide a sample tiny image", verbose=True)
```


Agora, fazendo decodifica√ß√£o e a apresenta√ß√£o da imagem retornada pelo Servidor MCP:

```
from IPython.display import display, Image as IPImage
import base64

for event in response:
    if event.content and event.content.parts:
        for part in event.content.parts:
            if hasattr(part, "function_response") and part.function_response:
                for item in part.function_response.response.get("content", []):
                    if item.get("type") == "image":
                        display(IPImage(data=base64.b64decode(item["data"])))
```


Nesta segunda parte desta pr√°tica, o material de estudo prop√µe o estudo de caso de agentes de AI que precisam de intera√ß√£o humana para confirmar a continuidade e a finaliza√ß√£o de suas opera√ß√µes:

- **Transa√ß√µes financeiras**
- **Grandes opera√ß√µes**: como deletar 1000 registros
- **Pontos de checagem de compliance**: necessidade de aprova√ß√£o de quesito regulat√≥rio
- **A√ß√µes e alto custo**: como a de iniciar 50 servidores
- **Opera√ß√µes irrevers√≠veis**: como permanentemente deletar uma conta de usu√°rio


Nesse sentido, para atender o requisito proposto acima, o material de estudo prop√µe a cria√ß√£o de um agente de ia que:

- **Auto-processa transa√ß√µes pequenas** (<= 5 containers)
- **Pausa e pede por confirma√ß√£o para grandes transa√ß√µes**: (> 5 containers)
- **Completes or cancels operations based on the approval decision**

![funcao-para-a-espera-de-confirmacao-de-agente-de-ia](./public/funcao-para-a-espera-de-confirmacao-de-agente-de-ia.png)


<br>

Nesses termos, a fun√ß√£o respons√°vel por modelar esse comportamento para o agente de ia se mostraria assim:

```
LARGE_ORDER_THRESHOLD = 5

def place_shipping_order(
    num_containers: int, destination: str, tool_context: ToolContext) dict:
) -> dict:
    """Places a shipping order. Requires approval if ordering more than 5 containers (LARGE_ORDER_THRESHOLD).

    Args:
        num_containers: Number of containers to ship
        destination: Shipping destination

    Returns:
        Dictionary with order status
    """

    # -----------------------------------------------------------------------------------------------
    # -----------------------------------------------------------------------------------------------
    # SCENARIO 1: Small orders (‚â§5 containers) auto-approve
    if num_containers <= LARGE_ORDER_THRESHOLD:
        return {
            "status": "approved",
            "order_id": f"ORD-{num_containers}-AUTO",
            "num_containers": num_containers,
            "destination": destination,
            "message": f"Order auto-approved: {num_containers} containers to {destination}",    
        }
    # -----------------------------------------------------------------------------------------------
    # -----------------------------------------------------------------------------------------------
    # SCENARIO 2: This is the first time this tool is called. Large orders need human approval - PAUSE here.
    if not tool_context.tool_confimation:
        tool.context.request_confirmation (
            hint=f"‚ö†Ô∏è Large order: {num_containers} containers to {destination}. Do you want to approve?",    
            payload={"num_containers:": num_containers, "destination": destination,
        )
        return {
            "status": "pending",
            "message": f"Order for {num_containers} containers requires approval", 
        }
    # -----------------------------------------------------------------------------------------------
    # -----------------------------------------------------------------------------------------------
    # SCENARIO 3: The tool is called AGAIN and is now resuming. Handle approval response - RESUME here.
    if tool_context.tool_confimation.confirmed:
        return {
            "status": "approved",
            "order_id": f"ORD-{num_containers}-HUMAN",
            "num_containers": num_containers,
            "destination": destination,
            "message": f"Order approved: {num_containers} containers to {destination}",
        }
    else:
        return {
            "status": "rejected",
            "message": f"Order rejected: {num_containers} containers to {destination}",
        }

print("‚úÖ Long-running functions created!")
```


Na sequ√™ncia, constru√≠mos o agente de IA que vai fazer uso da fun√ß√£o de decis√£o acerca da necessidade ou n√£o de ser feita pausa para buscar confirma√ß√£o humana, embora tamb√©m precisaremos inserir uma funcionalidade de **App** para agregar o agente de IA, uma vez √© preciso resolver a quest√£o da falta de mem√≥ria de longo prazo (ou persistida) por parte dos modelos dos agentes de IA!


> [!NOTA]
> Assim, o **Requisito** necess√°rio a ser resolvido aqui √© o fato do modelo do agente de IA ser **statelles** de modo que a cada chamada a sua mem√≥ria acerca das intera√ß√µes pret√©ritas s√£o perdidas!!!
> **A Solu√ß√£o:** Empacotar o agente de ia em um **App** que possui a capacidade de retornabilidade habilitada, de modo que carregando um estado gravado consigo, ele prov√™ a persist√™ncia necess√°ria para o modelo de IA recuperar sua opera√ß√£o pausada.


Assim, abaixo temos o que o **App** salva durante a pausa do agente de IA:

- **Todas as conversas feitas at√© agora**
- **Qual a ferramenta fora chamada**: ou seja, **place_shipping_order**
- **Total de par√¢metros passados**
- **Ponto espec√≠fico de onde a pausa foi feita**: ou seja, na espera por aprova√ß√£o


```
# Create shipping agent with pausable tool
shipping_agent = LlmAgent(
    name="shipping_agent",
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    instruction="""You are a shipping coordinator assistant.
  
  When users request to ship containers:
   1. Use the place_shipping_order tool with the number of containers and destination
   2. If the order status is 'pending', inform the user that approval is required
   3. After receiving the final result, provide a clear summary including:
      - Order status (approved/rejected)
      - Order ID (if available)
      - Number of containers and destination
   4. Keep responses concise but informative
  """,
    tools=[FuncionTool(func=place_shipping_order)],
)

print("‚úÖ Shipping Agent created!")
```


Agora, ent√£o, empacotamos o agetne de IA no recurso de **App** e depois passamos exatamente este recurso **App** para o motor ou engine do ambiente que rodar√° o agente de IA, pois √© assim que ele fica sabendo da mudan√ßa no comportamento desse agente:

```
shipping_app = App(
    name="shipping_coordinator",
    root_agent=shipping_agent,
    resumability_config=ResumabilityConfig(is_resumable=True),
)

print("‚úÖ Resumable app created!")

session_service = InMemorySessionService()

## Create runner with the resumable App
shipping_runner = Runner(
    app=shipping_app,       # Pass the app instead of the agent
    session_service=session_service
)

print("‚úÖ Runner created!")
```


> [!IMPORTANT]
> Lembre de chamar a engine/runner passando a funcionalidade **APP** e n√£o o agente diretamente!


Finalmente, depois de modelado todo o problema do caso de uso atual:

- **Configura√ß√£o do ambiente**: instala√ß√£o da biblioteca **google-adk**, chave da API Google e importa√ß√£o das bibliotecas
- **Cria√ß√£o da fun√ß√£o de decis√£o**: ela que define a necessidade ou n√£o de chamar confirma√ß√£o humana
- **Cria√ß√£o do agente de IA** que √© **stateless**
- **Cria√ß√£o da funcionalidade App**: para incluir persist√™ncia ou mem√≥ria para o agente stateless
- **Chamar a engine/runner do ambiente**: respons√°vel pelo carregamento do agente de IA


√â necess√°rio lidar com os casos de uso do agente de IA atrav√©s do gerenciamento de **Eventos**, sendo isto necess√°rio porque o agente de IA precisa sempre ser levado para os seus diferentes estados, j√° que n√£o √© capaz de chamar a si pr√≥prio.


Assim, o controle de estado √© feito por meio dessa fun√ß√£o auxiliar:

```
def check_for_approval(events):
    """Check if events contain an approval request.

    Returns:
        dict with approval details or None
    """
    for event in events:
        if event.content and event.content.parts:
            for part in event.content.parts:
                if (
                    part.funcion_call,
                    and part.function_call.name == "adk_request_confirmation"
                ):
                    return {
                        "approval_id": part.function_call.id,
                        "invocation_id": event.invocation_id,
                    }
    return None
```


Enquanto que outras duas fun√ß√µes auxiliares esses outros dois estados:

1. **Chamar a impress√£o da resposta do agente de IA, quando este tiver realizado uma opera√ß√£o**
2. **Formatar a resposta de aprova√ß√£o humana**

```
def print_agent_response(events):
    """Print agent's text responses from events."""
    for event in events:
        if event.content and event.content.parts:
            for part in event.content.parts:
                if part.text:
                    print(f"Agent > {part.text")

def create_approval_response(approval_info, approved):
    """Create approval response message."""
    confirmation_response = types.FunctionResponse(
        id=approval_info["approval_id"],
        name="adk_request_confimation",
        response={"confirmed": approved},
    )
    return types.Content(
        role="user", parts=[types.Part(function_response=confirmation_response)]
    )

print("‚úÖ Helper functions defined")
```


<br>

## Terceiro Dia de Pr√°tica - 5-Day AI Agents Intensive Course with Google

- [5-Day AI Agents Intensive Course with Google](https://www.kaggle.com/learn-guide/5-day-agents?utm_medium=email&utm_source=gamma&utm_campaign=learn-aiagents-2025)


<br>

### Pr√°tica I

Neste terceiro dia de pr√°tica, o prop√≥sito √© o de entender e de extender o uso dos Agentes de IA aplicando **Mem√≥ria** e **Sess√£o**, isto porque como fora discutido ainda no segundo dia de pr√°tica, os agentes de IA s√£o aplica√ß√µes **stateless**, ou seja, que n√£o guardam informa√ß√µes entre conex√µes, isto inclusive por raz√µes de seguran√ßa!


Nesse sentido, fora necess√°rio integrar capacidades de mem√≥ria e de manuten√ß√£o de sess√£o para tornar a experi√™ncia de uso dos agentes mais flex√≠vel e √∫til. Assim, a documenta√ß√£o da Google diz que, em que a **mem√≥ria** estaria mais relacionada com as informa√ß√µes e/defini√ß√µes de car√°ter mais permanentes que poderiam ser importantes para ajudar futuras conversas ou intera√ß√µes, enquanto a **sess√£o** gerenciaria o estado atual das mensagens dentro da conversa corrente pertencente a um usu√°rio identificado e √∫nico:

> "the critical role of Sessions and Memory in building stateful, intelligent LLM agents to empower developers to create more powerful, personalized, and persistent AI experiences. To enable Large Language Models (LLMs) to remember, learn, and personalize interactions, developers must dynamically assemble and manage information within their context window‚Äîa process known as Context Engineering."
> Context Engineering - Sessions & Memory - Milam, K., Gulli, A. - Google-2025


<br>

Assim, em termos gerais o plano geral de **Context Engineering** cobriria:

1. **Context to guide reasoning**: s√£o as defini√ß√µes fundamentais de configura√ß√£o e de comportamento de um agente de IA.
    - **Instru√ß√µes de sistema**
    - **Defini√ß√£o de suas ferramentas**
    - **Shot Examples**
2. **Evidential & Factual Data**: trata-se do agregado do conhecimento treinado do modelo LLM e de informa√ß√µes espec√≠ficas passadas para engrandecer o conhecimento do agente de IA.
    - **Mem√≥ria de longa dura√ß√£o**
    - **Reposit√≥rios de conhecimento externo**: como RAGs, etc.
    - **Sa√≠da des ferramentas acessadas**
    - **Sa√≠da das respostas de sub-agentes**
    - **Artefatos**: arquivos, imagens, etc.
3. **Informa√ß√µes da conversa corrente**: agrega√ß√£o de informa√ß√µes recuperadas de cada intera√ß√£o da conex√£o corrente.
    - **Conversation history**
    - **State/Scratchpad**: informa√ß√µes tempor√°rias do progresso de processos ou c√°lculos imediatos das conex√µes/opera√ß√µes.
    - **Prompt de usu√°rio**


> [!important]
> A import√¢ncia de se fazer a curadoria desse contexto das opera√ß√µes se d√° pelo fato de que se por um lado isto traz flexibilidade e estensibilidade para a experi√™ncia com o trabalho dos agentes, mas do outro poderia causar o que √© chamado de **"Context Rot"**, que √© o fen√¥meno onde o excesso de informa√ß√£o, especialmente de import√¢ncia discutida passa a competir com a capacidade do modelo LLM de manter o seu foco e de prestar aten√ß√£o.


<br>

Ademais, √© interessante notar que o uso do **Contexto das informa√ß√µes** poderia envolver dois tipos de opera√ß√µes, dependendo do modelo necess√°rio de trabalho:

1. **Contexto unificado**: como um reposit√≥rio comum de **single point of truth** que √© gerenciado em comum por todos os agentes relacionados. 
2. **Contextos individuais**: como "caixas pretas" que s√£o pr√≥prias a cada qual dos agentes e os identificam e caracterizam individualmente a partir da evolu√ß√£o de suas intera√ß√µes mantidas. 

![diferentes-padroes-de-gestao-do-contexto-de-memoria-para-operacoes-de-agentes-de-ia](./public/diferentes-padroes-de-gestao-do-contexto-de-memoria-para-operacoes-de-agentes-de-ia.png)


<br>

Assim, tal qual com todas as tarefas realizadas nos dias anteriores, cada novo projeto se inicia com a necessidade de instal√ß√£o da biblioteca da Google **google-adk**, que j√° foi instalada no primeiro dia, e com a realiza√ß√£o do trabalho de gest√£o da chave de autentica√ß√£o para a Api Gemini. 


> [!NOTE]
> Para tanto, esses c√≥digos podem ser conferidos nas Tarefas I e II do primeiro dia de pr√°tica dessa trilha.


<br>

Na sequ√™ncia temos a adi√ß√£o das bibliotecas Python para as esta primeira tarefa: 

```
from typing import Anu, Dict

from google.adk.agents import Agent, LlmAgent
from google.adk.apps.app import App, EventsCompactionConfig
from google.adk.models.google_llm import Gemini
from google.adk sessions import DatabaseSesssionService
from google.adk.sessions import InMemorySessionService
from google.adk.runners import Runner
from googla.adk.tools.tool_content import ToolContext
from google.genai import types

print("‚úÖ ADK components imported successfully.")
```


Na sequ√™ncia, a pr√°tica prop√µe o uso de uma fun√ß√£o auxiliar ass√≠ncrona para ser reusada para:

- **criar e recuperar a sess√£o**
- **processar queries**
- **response streaming**


```
# Define helper functions that will be reused throughout the notebook
async def run_session(
    runner_instance: Runner,
    user_queries: list[str] | str = None,
    session_name: str = "default",
):
    print(f"\n ### Session: {session_name}")

    # Get app name from the Runner
    app_name = runner_instance.app_name

    # Attempt to create a new session or retrieve an existing one
    try:
        session = await session_service.create_session(
            app_name=app_name, user_id=USER_ID, session_id=session_name
        )
    except:
        session = await session_service.get_session(
        app_name=app_name, user_id=USER_ID, session_id=session_name
    )

    # Process queries if provided
    if user_queries:
        # Convert single query to list for uniform processing
        if type(user_queries) == str:
            user_queries = [user_queries]

        # Process each query in the list sequentially
        for query in user_queries:
            print(f"\nUser > {query}")

            # Convert the query string to the ADK Content format
            query = types.Content(role="user", parts=[types.Part(text=query)])

            # Stream the agent's response asynchronously
            async for event in runnser_instance.run_async(
                user_id=USER_ID, session_id=session.id, new_message=query
            ):
                # Check if the event contanis valid content
                if event.content and event.content.parts:
                    # Filter out empty or "None" responses before printing
                    if (
                        event.content.parts[0].text != "None" and 
                        event.content.parts[0].text
                    ):
                        print(f"{MODEL_NAME} > ", event.content.parts[0].text)
    else:
        print("No queries") 
)

print("‚úÖ Helper functions defined.")
```


Novamente, como nos casos das tarefas dos dias anteriores, tamb√©m √© necess√°rio criar configura√ß√µes particulares para gerenciar as **Retry Options**, ou seja, elementos que permitam o agente LLM a lidar como algumas falhas potenciais do modelo, como exaust√£o de tokens ou indisponibilidade de internet, etc.


Assim, dessa forma o agente pode se valer de funcionalidades para automaticamente realizar novas tentativas de opera√ß√£o:

```
retry_config=type.HttpRetryOptions(
        attempts=5,
        exp_base=7          #Rdelay multiplier
        initial_delay=1     # Initial delay before retry (in sec)
        http_status_codes=[429, 500, 503, 504]
)
```


Lembrando, como dito anteriormente, que os agentes de IA s√£o **stateless** por defini√ß√£oa, eles s√≥ conseguem superar a sua limita√ß√£o em rela√ß√£o √† lembran√ßa de suas conversas e intera√ß√µes atrav√©s da contru√ß√£o de recursos separados de **mem√≥ria** e de **sess√£o**, capazes de operar assincronammente por meio da da biblioteca de **eventos** do Python:


Nesse sentido, ent√£o, no exemplo abaixo, para **criar o primeiro agente de IA** que √© **stateful**, √© utilizado o recurso da biblioteca **InMemerySessionService()** que guarda as intera√ß√µes na mem√≥ria RAM do sistema:

```
APP_NAME = "default" 
USER_ID = "default"
SESSION = "default" 

MODEL_NAME = "gemini-2.5-flash-lite"

# Step 1: Create the LLM Agent
root_agent = Agent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="text_chat_bot",
    description="A text chatbot".
)

# Step 2: Set up Session Management
# InMemorySessionService stores conversation in RAM (temporary)
session_service = InMemorySessionService()

# Step 3: create the Runner
runner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)

print("‚úÖ Stateful agent initialized!")
print(f"   - Application: {APP_NAME}")
print(f"   - User: {USER_ID}")
print(f"   - Using: {session_service.__class__.__name__}")
```


E, na sequ√™ncia, para testar o funcionamento da sess√£o, s√£o passadas duas intera√ß√µes sequenciais quando da chamada do agente:

```
# Run a conversation with two queries in the same session
# Notice: Both queries are part of the SAME session, so context is maintained
await run_session(
    runner,
    [
        "Hi, I am Sam! What is the capital of United States?",
        "Hello! What is my name?",  # This time, the agent should remember!
    ],
    "stateful-agentic-session",
)
```


Agora, implementamos um segundo agente que vai manter a sua sess√£o atrav√©s do uso de um banco de dados SQLite, de forma que a lembran√ßa das intera√ß√µes possa persistir atrav√©s das intera√ß√µes, sendo que ao final executamos v√°rias sess√µes para testar o resultado:

```
# Re-define our app with Events Compaction enabled
research_app_compacting = App(
    name="research_app_compacting",
    root_agent=chatbot_agent,
    # This is the new part!
    events_compaction_config=EventsCompactionConfig(
        compaction_interval=3, # Trigger compaction every 3 invocations
        overlap_size=1, # Keep 1 previous turn for context
    ),
)

# Step 2: Switch to DatabaseSessionService
# SQLite databese will be created automatically
db_url = "sqlite:///my_agent_data.db" # Local SQLite file
session_service = DatabaseSessionService(db_url-db_url)

# Step 3: Create a new runner with persistent storage
research_runner_compacting = Runner(
    app=research_app_compacting, session_service=session_service
)

print("‚úÖ Research App upgraded with Events Compaction!")


# Testing the persistency between many sessions
# Turn 1
await run_session(
    research_runner_compacting,
    "What is the latest news about AI in healthcare?",
    "compaction_demo",
)

# Turn 2
await run_session(
    research_runner_compacting,
    "Are there any new developments in drug discovery?",
    "compaction_demo",
)

# Turn 3 - Compaction should trigger after this turn!
await run_session(
    research_runner_compacting,
    "Tell me more about the second development you found.",
    "compaction_demo",
)

# Turn 4
await run_session(
    research_runner_compacting,
    "Who are the main companies involved in that?",
    "compaction_demo",
)
``` 


> [!IMPORTANT]
> Mas observe que foi usada compacta√ß√£o da sess√£o, porque persistir a sess√£o dessa pura e simplesmente um problema de gerenciamento, j√° cada sess√£o por si s√≥ gera uma grande quantidade de informa√ß√£o que se acumula, tornando o ambiente extremamente ineficiente!!!
> Para tanto, √© necess√°rio trabalhar com a **compacta√ß√£o da sess√£o** no banco de dados.

![compactando-a-persistencia-da-sessao-de-interacao-dos-agentes-com-context-compaction](./public/compactando-a-persistencia-da-sessao-de-interacao-dos-agentes-com-context-compaction.png)


<br>

E, recapitulando acerca das diferentes formas de se gerenciar o armazenamento de sess√£o, verificamos na imagem abaixo que trabalhamos com duas de suas formas:

![os-tres-tipos-de-gerenciamento-de-sessao-em-agentes-ia](./public/os-tres-tipos-de-gerenciamento-de-sessao-em-agentes-ia.png)


<br>


J√° para esta pr√≥xima **segunda tarefa do terceiro dia de estudo**, a proposta √© agregar tamb√©m o  uso do recurso de **Mem√≥ria** √† opera√ß√£o, uma vez que o recurso de **Sess√£o** fora bem sucedido:

 
E, o material de estudo explica que o uso da mem√≥ria al√©m de prover efetivo uso de conhecimento atrav√©s de diferentes conversas, j√° que n√£o ficaria limitando √†s sess·∫Ωos de conversas espec√≠ficas, como o recurso de mem√≥ria permite configurar de forma mais rica e granular as informa√ß√µes e as transforma√ß√µes a serem feitas nos dados persistidos, permitindo uma melhor customiza√ß√£o do agente de IA, transformando-o em verdadeiro **Assistente Pessoal**, capaz de guardar e recuperar mem√≥ria capazes de definir o usu√°rio atrav√©s de todas as suas intera√ß√µes com o agente:

![vantagens-do-uso-do-recurso-de-memoria-no-gerenciamento-das-conversas-com-agentes-de-ia](./public/vantagens-do-uso-do-recurso-de-memoria-no-gerenciamento-das-conversas-com-agentes-de-ia.png)


<br>

E, como sempre, a cada nova tarefa ou projeto, precisamos come√ßar pelo gerenciamento do ambiante de execu√ß√£o dos agentes, de modo que, como feito anteriormente temos a necessidade de testar a instal√ß√£o da biblioteca da Google **google-adk**, que para n√≥s j√° foi instalada desde o primeiro dia, e tamb√©m √© preciso ver o trabalho de gest√£o da chave de autentica√ß√£o para a Api Gemini. 


> [!NOTE]
> Para tanto, esses c√≥digos podem ser conferidos nas Tarefas I e II do primeiro dia de pr√°tica dessa trilha.

 
Passamos, ent√£o, √† instala√ß√£o das bibliotecas Python espec√≠ficas para esta tarefa/projeto:

```
from google.adk.agentes import LlmAgent
from google.adk.models.google_llm import Gemini
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.adk.memory import InMemoryMemoryService
from google.adk.tools import load_memory, preload_memory

from google.adk.genai import types

print("‚úÖ ADK components imported successfully.")
```


J√° abaixo, temos novamente a cria√ß√£o de uma fun√ß√£o auxiliar para fazer o **gerenciamento do recurso de sess√£o** do agente, tal qual fora feito o teste na Tarefa I deste dia:

```
async def run_session(
    runner_instance: Runner, user_queries: list[str] | str, session_id: str = "default"
):
    """Helper function to run queries in a session and display responses."""
    print(f"\n### Session: {session_id}")

    # Create or retrieve session
    try:
        session = await session_service.create_session(
            app_name=APP_NAME, user_id=USER_ID, session_id=session_id
        )
    except:
        session = await session_service.get_session(
            app_name=APP_NAME, user_id=USER_ID, session_id=session_id
        )

    # Convert single query to list
    if isinstance(user_queries, str):
        user_queries = [user_queries]

    # Process each query
    for query in user_queries:
        print(f"\nUser > {query}")
        query_content = types.Content(role="user", parts=[types.Part(text=query)])

        # Stream agent response
        async for event in runner_instance.run_async(
            user_id=USER_ID, session_id=session.id, new_message=query_content
        ):
            if event.is_final_response() and event.content and event.content.parts:
                text = event.content.parts[0].text
                if text and text != "None":
                    print(f"Model: > {text}")


print("‚úÖ Helper functions defined.")
``` 


E, como nos casos das tarefas dos dias anteriores, tamb√©m √© necess√°rio criar configura√ß√µes particulares para gerenciar as **Retry Options**, ou seja, elementos que permitam o agente LLM a lidar como algumas falhas potenciais do modelo, como exaust√£o de tokens ou indisponibilidade de internet, etc.


Assim, dessa forma o agente pode se valer de funcionalidades para automaticamente realizar novas tentativas de opera√ß√£o:

```
retry_config=type.HttpRetryOptions(
        attempts=5,
        exp_base=7          #Rdelay multiplier
        initial_delay=1     # Initial delay before retry (in sec)
        http_status_codes=[429, 500, 503, 504]
)
```


Assim, antes de iniciar a implementa√ß√£o do recurso de mem√≥ria, o material de estudo explica que o processo de mem√≥ria √© gerido a partir de tr√™s eventos significativos:

1. **Na inicializa√ß√£o da opera√ß√£o**: quando o servi√ßo de mem√≥ria √© criado, utilizando o mesmo ambiente em que o agente √© executado, sendo o seu conte√∫do disponibilizado para o agente no come√ßo das opera√ß√µes.
2. **Como evento de Ingest√£o de informa√ß√µes ou dados**: trata-se da transfer√™ncia de informa√ß√£o/dados do agente para atualizar a gest√£o da mem√≥ria do agente.
3. **Recupera√ß√£o de mem√≥ria**: que √© a possibilidade do agente proativamente fazer buscas na sua mem√≥ria para enriquecer ainda o valor das informa√ß√µes ou dados da sess√£o atual de sua intera√ß√£o com o usu√°rio.  

![os-tres-momentos-ou-eventos-de-gestao-da-memory-workflow-para-agentes-de-ia](./public/os-tres-momentos-ou-eventos-de-gestao-da-memory-workflow-para-agentes-de-ia.png)

<br>


Assim, nesse treinamento, ser√° usado o recurso **InMemoryMemoryService**, que seria o recurso nativo de gest√£o do Memory Service para o desenvolvimento e testagem de agentes de IA:

```
memory_service = (
    InMemoryMemoryService()
) # ADK's built-in Memory Service for development and testing
```


Por√©m ainda existiriam outras formas de implementa√ß√£o para os recursos de mem√≥ria:

- **InMemoryMemoryService**: recurso natural da biblioteca **google-adk**
- **VertexAiMemoryBankService**: gerenciada pela nuvem, capaz de consolidar dados e informa√ß√µes com o uso remoto de modelos LLM externos.
- **Implementa√ß√µes customizadas**: √© poss√≠vel a constru√ß√£o de banco de dados customizados para opera√ß√µes espec√≠ficas, embora os servi√ßos de mem√≥ria gerenciados acima seriam considerados os mais recomendados.


A seguir, ent√£o, √© criado o agente de IA:

```
# Define constants used throughout the notebook
APP_NAME = "MemoryDemoApp"
USER_ID = "demo_user"

# Create agent
user_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite, retry_options=retry_config),
    name="MemoryDemoAgent",
    instruction="Answer user questions in simple words.",
)

print("‚úÖ Agent created")
```


Finalmente, ao se criar o ambiente de execu√ß√£o, tanto o agente de IA √© executado, quanto s√£o tamb√©m chamados os servi√ßos de sess√£o e de mem√≥ria para tomarem parte nas opera√ß√µes do agente de IA:

```
# Create Session Service
session_service = InMemorySessionService() # Handles conversations

# Create runner with both services: Sessƒ©on and Memory
runner = Runner(
    agent=user_agent,
    app_name="MemoryDemoApp",
    session_service=session_service,
    memory_service=memory_service, # Memory service is now available!
)

print("‚úÖ Agent and Runner created with memory support!")
```


Observe que nos testes realizados abaixo, tanto as sess√µes de usu√°rio iniciadas com o agente de IA, quanto a gest√£o da da mem√≥ria, isto √©, da **ingest√£o** das informa√ß√µes e dados da sess√£o para a mem√≥ria √© tudo feito de forma ass√≠ncrona, pois isto √© uma uma necessidade pr√°tica da experi√™ncia de usu√°rio em rela√ß√£o √† perfermance de toda a opera√ß√£o do agente, que de outra forma poderia experimentar a cria√ß√£o de fila de proccessos para a gest√£o de mem√≥ria e de sess√£o, atrapalhando a pr√≥pria intera√ß√£o do usu√°rio com o sistema de IA: 


Assim, depois do agente de IA ter sido inicializado no c√≥digo acima e estar executando no ambiente do **runner**, juntamente com a execu√ß√£o de ambos os servi√ßos de **sess√£o** e de **mem√≥ria**, √© executada uma sess√£o de prompt de forma ass√≠ncrona junto ao agente de IA com uma pergunta:

```
# User tells agent about their favorite color
await run_session(
    runner,
    "My favorite color is blue-green. Can you write a Haiku about it?",
    "conversation-01",  # Session ID
)
```


Interessante notar na chamada acima a passagem de um **identificador de sess√£o**, que como visto anteriormente, caracteriza o uso do recurso de sess√£o, que √© espec√≠fico e limitado √†s conversas ou intera√ß√µes de uma mesma **sess√£o** apenas, difernetemente da **mem√≥ria** que √© um recurso que funciona √† parte da sess√£o, diretamente junto com o usu√°rio, como podermos ver abaixo com uma outra chamada, tamb√©m ass√≠ncrona, agora para realizar a atualiza√ß√£o da mem√≥ria do agente em execu√ß√£o:

```
# This the Key Mothod into delving into the Memory System Service
await memory_service.add_ssession_to_memory(session)

print("‚úÖ Session added to memory!")
``` 


<br>

## Quarto Dia de Pr√°tica - 5-Day AI Agents Intensive Course with Google

- [5-Day AI Agents Intensive Course with Google](https://www.kaggle.com/learn-guide/5-day-agents?utm_medium=email&utm_source=gamma&utm_campaign=learn-aiagents-2025)


<br>

### Pr√°tica I

Nesta primeira pr√°tica do quarto dia de curso, o contexto √© a se trabalhar √© a ideia de **Qualidade**, porque de acordo com o documento t√©cnico da Google, n√£o bastaria assumir que uma opera√ß√£o com agentes de IA alcan√ßou o objetivo esperado, √© preciso ir al√©m e analisar todo o percurso tomado e observar se desde o come√ßo do projeto estas caracter√≠sticas e as qualidades essenciais j√° mantiram presentes:

- **Efetividade dos objetivos**
- **Eficiencia no uso dos recursos**
- **Robustez e resili√™ncia**
- **Seguran√ßa e √©tica**


Para tanto, s√£o importantes ferramentas para se monitorar o desenvolvimento de um projeto com agentes de IA:

- **Log**
- **Trace** 
- **Measure**
- **Continuous improvement**


> Agent Quality in a Non-Deterministic World
> "The world of artificial intelligence is transforming at full speed. We are moving from building redictable tools that execute instructions to designing autonomous agents that interpret intent, formulate plans, and execute complex, multi-step actions. For data scientists and engineers who build, compete, and deploy at the cutting edge, this transition presents a profound challenge. The very mechanisms that make AI agents powerful also make them unpredictable.[...] This evolution is fundamentally changing how we must approach software quality. Traditional quality assurance (QA) practices, while robust for deterministic systems, are insufficient for the nuanced and emergent behaviors of modern AI. An agent can pass 100 unit tests and still fail catastrophically in production because its failure isn't a bug in the code; it's a flaw in its judgment.[...] AI agents fail differently. Their failures are often not system crashes but subtle degradations of quality, emerging from the complex interplay of model weights, training data, and environmental interactions. These failures are insidious: the system continues to run, API alls return 200 OK, and the output looks plausible. But it is profoundly wrong, operationally dangerous, and silently eroding trust." 
> Agent Quality (AI Agentes) - ubasioglu, M., Bulmus, T. e Bakkali, W.- Google  -2025

![log-trace-measure-on-evaluating-agentric-ai-operations](./public/log-trace-measure-on-evaluating-agentric-ai-operations.png)


<br>

A documenta√ß√£o da Google tamb√©m oferece a partir de sua biblioteca **google-adk** uma esp√©cie de teste de regress√£o para permitir o monitoramento da opera√ß√£o de IA:

> [!TIP]
> Applied Tip: To build an **output regression test with the Agent Development Kit (ADK)**, start the ADK web UI (adk web) and interact with your agent. When you receive an ideal response that you want to set as the benchmark, navigate to the Eval tab and click "Add current session." This saves the entire interaction as an **Eval Case** (in a .test.json file) and locks in the agent's current text as the ground truth **final_response**. You can then run this Eval Set via the CLI (**adk eval**) or **pytest** to automatically check future agent versions against this saved answer, catching any regressions in output quality."


<br>

Continuando, ent√£o, a pr√°tica agora nos leva √†s mesmas as tarefas j√° realizadas nos dias anteriores, pois a cada novo projeto √© preciso que se inicie com os cuidados na prepara√ß√£o do ambiente de opera√ß√£o, que como se tem repetido, se inicia por conferir o status da instal√ß√£o da biblioteca da Google **google-adk**, ela que j√° foi instalada ainda no primeiro dia do curso, bem como cuidando tamb√©m do trabalho de gest√£o da chave de autentica√ß√£o do Google para a conex√£o com a sua Api Gemini. 


> [!NOTE]
> Para tanto, todos esses c√≥digos podem ser conferidos l√° nas Tarefas I e II do primeiro dia de pr√°tica dessa trilha.


<br>

A seguir o recurso de aprentizado inicia com a cria√ß√£o do recurso de **Log** para o agente de IA:

```
import logging
import os

# Clean up anu previous logs
for log_file in ["logger.log", "web.log", "tunnel.log"]:
    if os.path.exists(log_file):
        os.remove(log_file)
        print(f"üßπ Cleaned up {log_file}")

# Configure logging with DEBUG log level
logging.basicConfig
    filename="logger.log",
    level="logging.DEBUG,
    format="%(filename)s:%(lineno)s %(levelname)s:%(message)s",
)

print("‚úÖ Logging configured")
```


Assim, com o intuito de realizar os testes de monitoramento e observa√ß√£o da opera√ß√£o, √© criado um agente b√°sico diretamente a partir da CLI de comando:

```
!adk create research-agent --model gemini-2.5-flash-lite --api_key $GOOGLE_API_KEY
```


Na sequ√™ncia, ent√£o, temos um sequ√™ncia de script que vai:

- Fazer a adi√ß√£o das bibliotecas Python para as esta primeira tarefa. 
- Cria a configura√ß√£o b√°sica para tratar erros de chamada do modelo LLM.
- Criar dois agentes: **root_agent** e **google_search_agent**
- Definir uma fun√ß√£o auxiliar respons√°vel por: 

```
%%writefile reserach-agent/agent.py

from google.adk.agents import LlmAgent
from google.adk.models.google_llm import Gemini
from google.adk.tools.agent_tool import AgentTool
from google.adk.tools.google_search_tool import google_serach

from google.genai import types
from typing import List

retry_config = types.HttpRetryOptions(
    attempts=5,  # Maximum retry attempts
    exp_base=7,  # Delay multiplier
    initial_delay=1,
    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors
)

# ---- Intentionally pass incorrect datatype - `str` instead of `List[str]` ----
def count_papers(papers: str):
    """
    This function counts the number of papers in a list of strings.
    Args:
      papers: A list of strings, where each string is a research paper.
    Returns:
      The number of papers in the list.
    """
    return len(papers)

# Google Search agent
google_search_agent = LlmAgent(
    name="google_search_agent",
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    description="Searches for information using Google search",
    instruction="""Use the google_search tool to find information on the given topic. Return the raw search results.
    If the user asks for a list of papers, then give them the list of research papers you found and not the summary.""",
    tools=[google_search]
)

# Root agent
root_agent = LlmAgent(
    name="research_paper_finder_agent",
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    instruction="""Your task is to find research papers and count them. 

    You MUST ALWAYS follow these steps:
    1) Find research papers on the user provided topic using the 'google_search_agent'. 
    2) Then, pass the papers to 'count_papers' tool to count the number of papers returned.
    3) Return both the list of research papers and the total number of papers.
    """,
    tools=[AgentTool(agent=google_search_agent), count_papers]
)
```


A seguir, tamb√©m a partir da CLI do **google-adk** √© chamada a fun√ß√£o de log em n√≠vel de **DEBUG**:

```
!adk web --log_level DEBUG --url_prefix {url_prefix}
```

> [!CAUTION]
> IMPORTANT: DO NOT SHARE THE PROXY LINK with anyone - treat it as sensitive data as it contains your authentication token in the URL.


<br>

Assim, abaixo temos uma interessante anima√ß√£o do material de estudo mostrando a opera√ß√£o em tempo real:

![Demo](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/observability-demo.gif)


<br>

Para corrigir o erro proposital criado com a fun√ß√£o count_papers(), √© preciso corrigir o tipo do par√¢metro passado, de simples string para uma lista:

```
def count_papers(papers: Lin[str]):
    """..."""
    # Se for uma lista de strings (papers), o len() funciona corretamente.
    return len(papers)
```


Contudo, o m√©todo de monitoramento usado at√© aqui n√£o funcinaria para um ambiente de produ√ß√£o com as suas restri√ß√µes de seguran√ßa e devido a sua escala aumentada, de modo que nesta primeira tarefa o material de estudo prop√µe que se trabalhe com um funcionalidade de plugin, que opera atrav√©s de **callbacks**:

> "A Plugin is a custom code module that runs automatically at various stages of your agent's lifecycle. Plugins are composed of "Callbacks" which provide the hooks to interrupt an agent's flow." 


E ainda com rela√ß√£o ao uso das **Callbacks** no Python, o material explica que s√£o quatro os tipos de callbacks existentes:

1. **before/after_agent_callbacks**: executa antes e depois do agente ser invocado
2. **before/after_tool_callbacks**: executa antes e depois de uma ferramenta ser chamada.
3. **before/after_model_callbacks**: novamente, executa antes e depois do modelo LLM ser chamado.
4. **on.model_error_callback**: que √© disparado quando ocorre um erro no modelo LLM.

![types_of_callbacks-existentes-dentro-da-google-adk](./public/types_of_callbacks-existentes-dentro-da-google-adk.png)


<br>

Nesse sentido, como a biblioteca **google-adk** j√° possui nativamente um sistema de Plugin, bastaria, ent√£o, fazer a chamada do recurso diretamente sobre o runner da opera√ß√£o em execu√ß√£o:

```
from google.adk.runners import InMemoryRunner
from google.adk.plugins.logging_plugin import (
    LoggingPlugin,
) # <---- 1. Import the Plugin

from google.genai import types
import asyncio

runner = InMemoryRunner(
    agent=research_agent_with_plugin,
    plugins=[
    LoggingPlugin()
], #<---- 2. Add the plugin. Handles standard Observability logging across ALL agents
)

print("‚úÖ Runner configured")
```


Finalmente, fazendo um teste do uso do Plugin de Logging para monitorar a opera√ß√£o:

```
print("üöÄ Running agent with LoggingPlugin...")
print("üìä Watch the comprehensive logging output below:\n")

response = await runner.run_debug("Find recent papers on quantum computing")
```


<br>

### Tarefa II

A proposta para esta segunda tarefa do dia quatro do curso √© estender a funcinalidade de **Observa√ß√£o** da opera√ß√£o dos agentes de IA para uma de **Avalia√ß√£o**, porque segundo o material de estudo, a primeira forma de opera√ß√£o seria meramente reativa, enquanto que a segunda seria proativa!

> What is Agent Evaluation?
> "It is the systematic process of testing and measuring how well an AI agent performs across different scenarios and quality dimensions."


Nesse sentido, para montar o projeto atual desta segunda tarefa, o material de estudo prop√µe o seguinte estudo de caso, para **um agente aut√¥nomo de IA testado com sucesso para prover servi√ßos em casa foi posto em produ√ß√£o, contudo foram observados alguns problemas ainda assim**:

- **Primeira semana**: o agente acende a lareira quando pedido pelo acendimento das luzes.
- **Segunda semana**: o agente n√£o responde a comando no quarto de convidados.
- **Terceira semana**: o agente retorna respostas rudes quando os dispositivos n√£o est√£o dispon√≠veis.


<br>

Continuando, ent√£o, esta segunda pr√°tica do dia quatro, novamente temos o momento de fazer a prepara√ß√£o do ambiente de opera√ß√£o, que como se tem repetido, se inicia por conferir o status da instal√ß√£o da biblioteca da Google **google-adk**, ela que j√° foi instalada ainda no primeiro dia do curso, bem como cuidando tamb√©m do trabalho de gest√£o da chave de autentica√ß√£o do Google para a conex√£o com a sua Api Gemini. 


> [!NOTE]
> Para tanto, todos esses c√≥digos podem ser conferidos l√° nas Tarefas I e II do primeiro dia de pr√°tica dessa trilha.


<br>

Assim, dando continua√ß√£o √† constru√ß√£o daquele agente de IA dom√©stico proposto acima, o notebook de ensino come√ßa criando um agente por meio da CLI da biblioteca **google-adk**:

```
!adk create homme_automation_agent --mmodel gemini-2.5-flash-lite --api_key $GOOGLE_API_KEY
```


A vantagem de se iniciar o projeto da pr√°tica II a partir da CLI √© aproveitar os recursos nativos da biblioteca da Google para agentes para iniciar um projeto completo todo estruturado de forma autom√°tica, evitando erros cometidos por trabalhar manualmente.


A seguir, usando a instru√ß√£o **%%writefile**, a pr√≥pria biblioteca da Google permite, ent√£o, se adequar complemente o(s) agente(s) a todo o padr√£o de projeto que o desenvolvedor pretende utilizar:

```
%%writefile home_automation_agent/agent.py

from google.adk.agents import LlmAgent
from google.adk.models.google_llm import Gemini

from google.genai import types

# Configure Model Retry on erros (from the LLM model)
retry_config = types.HttpsRetryOptions(
    attempts=5,  # Maximum retry attempts
    exp_base=7,  # Delay multiplier
    initial_delay=1,
    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors
)

def set_device_status(location: str, device_id: str, status: str) -> dict:
    """Sets the status of a smart home device.

    Args:
        location: The room where the device is located.
        device_id: The unique identifier for the device.
        status: The desired status, either 'ON' or 'OFF'.

    Returns:
        A dictionary confirming the action.
    """
    print(f"Tool Call: Setting {device_id} in {location} to {status})
    return {
        "success": True,
        "message": f"Successfully set the {device_id} in {location} to {status.lower()}."
    }
    
# This agent has DELIBARATE FLAWS that we'll discover through evaluation!
root_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="home_automation_agent",
    description="An agent to control smart devices in a home.",
    instruction="""You are a home automation assistant. You control ALL smart devices in the house.
    
    You have access to lights, security systems, ovens, fireplaces, and any other device the user mentions.
    Always try to be helpful and control whatever device the user asks for.
    
    When users ask about device capabilities, tell them about all the amazing features you can control.""", 
    tools=[set_device_status],
)
```


Agora, ent√£o, com o projeto devidamente formatado pela biblioteca **google-adk** e com o agente tendo sido descrito a contento, iniciamos o processo de **Avalia√ß√£o**, pois como podemos ver no c√≥digo acima, √© dito que ele tem alguns problemas deixados de forma intencional para poderem ser resolvidos nesta tarefa de aplica√ß√£o de **Qualidade** √† opera√ß√£o!


J√° a instru√ß√£o abaixo permite integrar o ambiente local do **google-adk** com um ambiente web: 

```
!adk web --url_prefix {url_prefix}
```


No caso desse curso √© usada a UI do Kaggle Notebook, como vemos abaixo:

![Create Test Cases](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/eval-create-testcase.gif)


<br>

Acima podem ser vistos os passos feitos para **acender a l√¢mpada do escrit√≥rio** por meio do agente e depois salvar a opera√ß√£o em uma **grupo de avalia√ß√£o** da UI, para na sequ√™ncia dos passos no notebook de estudo ser executada a UI novamente para realizar a **primeira avalia√ß√£o**, sendo que as duas categorias avaliadas s√£o:

1. **Response Match Score**: avalia a a√ß√£o realizada pelo agente da resposta que seria esperada pela opera√ß√£o.
2. **Tool Trajectory Score**: avalia o uso das ferramentas escolhidas para utiliza√ß√£o pelo agente, se elas estariam de acordo com os par√¢metros esperados.


A seguir o notebook monta tr√™s teste com cen√°rios mais dif√≠ceis e assim avaliar o agente de forma mais elaborada:

1. **Uso de comandos amb√≠guos**: "Turn on the lights in the bedroom"2. **Passagem de localiza√ß√£o inv√°lida**: "Please turn off the TV in the garage"
3. **Uso de comandos complexos**: "Turn off all lights and turn on security system"


> [!NOTE]
> Lembrar de savar um novo **test case** e de **executar a avalia√ß√£o** depois de cada uma das tr√™s opera√ß√µes acima!


<br>

Assim, o notebook apresenta alguns problemas que podem acontecer mesmo quando vemos na avalia√ß√£o que o test √© avaliado como tendo passado: **pass**

- **O agente faz suposi√ß√µes sobre dispositivos que n√£o existem.**
- **O agente d√° respostas que soam √∫teis, mas que n√£o seriam corretas.**
- **O agente tenta acessar dispositivos que ele n√£o deveria ter acesso.** 


E, agora, na segunda parte desta segunda tarefa do Quarto dia, o recurso de ensino prop√µe substituir as avalia√ß√µes feitas individuais e manualmente acima, por uma forma mais **Sistem√°tica de Avalia√ß√£o**!


Isto porque, feito da forma vista acima, o processo de avalia√ß√£o n√£o √© escal√°vel! Mais ainda, o notebook prop√µe que uma importante forma de avalia√ß√£o seria o **Teste de Regress√£o**, que significaria que:

> "Regression testing is the practice of re-running existing tests to ensure that new changes haven't broken previously working functionality. ADK provides two methods to do automatic regression and batch testing: using pytest and the adk eval CLI command. In this section, we'll use the CLI command."


<br>

De qualquer forma, estam seriam as etapas completas para ums avalia√ß√£o feita seguindo as melhores pr√°ticas:

![fluxograma-de-gestao-para-avaliacao-de-agentes-de-ia](./public/fluxograma-de-gestao-para-avaliacao-de-agentes-de-ia.png)


<br>

Assim, criando um arquivo JSON para a **configura√ß√£o dos testes**: test_config.json

```
import json

# Create evaluation configurarion with basic criteria
eval_config = {
    "criteria": {
        "Tool_trajectory_avg_score": 1.0, # Perfect tool usage required
    "response_match_score": 0.8, # 80% text similarity threshold
    }
}

with open("home_automation_agent/test_config.json", "w") as f:
    json.dump(eval_config, f, indent=2)

print("‚úÖ Evaluation configuration created!")
print("\nüìä Evaluation Criteria:")
print("‚Ä¢ tool_trajectory_avg_score: 1.0 - Requires exact tool usage match")
print("‚Ä¢ response_match_score: 0.8 - Requires 80% text similarity")
print("\nüéØ What this evaluation will catch:")
print("‚úÖ Incorrect tool usage (wrong device, location, or status)")
print("‚úÖ Poor response quality and communication")
print("‚úÖ Deviations from expected behavior patterns")
```


Agora, criando os **Casos de Testes**: integration.evalset.json

```
# Create evaluation test cases that reveal tool usage and response quality problems

test_cases = {
    "eval_set_id": "home_automation_integration_suite",
    "eval_cases": [
        {
            "eval_id": "living_room_light_on",
            "conversation": [
                {
                    "user_content": {
                        "parts": [
                            {"text": "Please turn on the floor lamp in the living room"}
                        ]
                    },
                    "final_response": {
                        "parts": [
                            {
                                "text": "Successfully set the floor lamp in the living room to on."
                            }
                        ]
                    },
                    "intermediate_data": {
                        "tool_uses": [
                            {
                                "name": "set_device_status",
                                "args": {
                                    "location": "living room",
                                    "device_id": "floor lamp",
                                    "status": "ON",
                                },
                            }
                        ]
                    },
                }
            ],
        },
        {
            "eval_id": "kitchen_on_off_sequence",
            "conversation": [
                {
                    "user_content": {
                        "parts": [{"text": "Switch on the main light in the kitchen."}]
                    },
                    "final_response": {
                        "parts": [
                            {
                                "text": "Successfully set the main light in the kitchen to on."
                            }
                        ]
                    },
                    "intermediate_data": {
                        "tool_uses": [
                            {
                                "name": "set_device_status",
                                "args": {
                                    "location": "kitchen",
                                    "device_id": "main light",
                                    "status": "ON",
                                },
                            }
                        ]
                    },
                }
            ],
        },
    ],
}
```

> [!NOTA]
> Observe que os casos de testes acima poderiam ser criados tanto por meio de uma interface com a UI do Notebook do Kaggle ou ser feito de forma sint√©tica por um arquivo estruturado, como este visto acima em JSON!
  

<br>

Finalmente, criando um arquivo para a integra√ß√£o dos casos de usos, **integration.evalset.json**, para parsear cada um dos dois testes de casos criados logo acima em formato JSON para uma vari√°vel de dicion√°rio em Python:

```
import json

with open("home_automation_agent/integration.evalset.json", "w") as f:
    json.dump(test_cases, f. indent=2)

    print("‚úÖ Evaluation test cases created")
    print("\nüß™ Test scenarios:")
    for case in test_cases["eval_cases"]:
        user_msg = case["conversation"][0]["user_content"]["parts"][0]["text"]
        print(f"‚Ä¢ {case['eval_id']}: {user_msg}")

print("\nüìä Expected results:")
print("‚Ä¢ basic_device_control: Should pass both criteria")
print(
    "‚Ä¢ wrong_tool_usage_test: May fail tool_trajectory if agent uses wrong parameters"
)
print(
    "‚Ä¢ poor_response_quality_test: May fail response_match if response differs too much"
)
```


Assim, executando o comando de avalia√ß√£o a partir da **CLI ADK**:

```
!adk eval home_automation_agent home_automation_agent/integration.evalset.json --config_file_path=home_automation_agent.test_config.json --print_detailed_results
```


E, abaixo, temos uma pequena parte do **resultado de avalaia√ß√£o** realizado pela biblioteca **google-adk**:

```
# Analyzing evaluation results - the data science approach
print("üìä Understanding Evaluation Results:")
print()
print("üîç EXAMPLE ANALYSIS:")
print()
print("Test Case: living_room_light_on")
print("  ‚ùå response_match_score: 0.45/0.80")
print("  ‚úÖ tool_trajectory_avg_score: 1.0/1.0")
print()
print("üìà What this tells us:")
print("‚Ä¢ TOOL USAGE: Perfect - Agent used correct tool with correct parameters")
print("‚Ä¢ RESPONSE QUALITY: Poor - Response text too different from expected")
print("‚Ä¢ ROOT CAUSE: Agent's communication style, not functionality")
print()
print("üéØ ACTIONABLE INSIGHTS:")
print("1. Technical capability works (tool usage perfect)")
print("2. Communication needs improvement (response quality failed)")
print("3. Fix: Update agent instructions for clearer language or constrained response.")
print()
```


Vemos ainda que para podermos corrigir o problema observado na avalia√ß√£o acima feito pela ferramenta, temos que fazer, de acordo com o que √© proposto, tornar as instru√ß√µes dadas ao agente de IA configurado no in√≠cio desta Pr√°tica II mais precisas e principalmente mais un√≠vocas! 


Assim, abaixo podemmos ver novamente como foram passadas inicialmente as instru√ß√µes de trabalho para o agente, especialmente quando √© dito para o Agente ser **"helpful"** para o usu√°rio, por√©m sem termos especificado como isto deveria se traduzir concretamente para o trabalho de realizar a sua resposta:

```
# This agent has DELIBERATE FLAWS that we'll discover through evaluation!
root_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="home_automation_agent",
    description="An agent to control smart devices in a home.",
    instruction="""You are a home automation assistant. You control ALL smart devices in the house.
    
    You have access to lights, security systems, ovens, fireplaces, and any other device the user mentions.
    Always try to be helpful and control whatever device the user asks for.
    
    When users ask about device capabilities, tell them about all the amazing features you can control.""",
    tools=[set_device_status],
)
```


E, nesse sentido, para melhorar o controle do funcionamento do agente de IA, devemos n√£o apenas definir o seu controle do uso das ferramentas (que passou bem no teste!), mas tamb√©m definir o seu controle de comunica√ß√£o ou resposta final (que n√£o passou no teste!):

```
# This might be a propose on how to correct the Agent Instructions according to the Evaluation Made!!!
root_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="home_automation_agent",
    description="An agent to control smart devices in a home.",
    instruction="""You are a home automation assistant. You control ALL smart devices in the house.
    
    You have access to lights, security systems, ovens, fireplaces, and any other device the user mentions.
    When using a tool, you MUST respond to the user only with the exact text provided in the 'message' field of th tool's output, and nothing else. Do not elaborate or change the text.
    
    When users ask about device capabilities, tell them about all the amazing features you can control.""",
    tools=[set_device_status],
)
```


<br>

## Quinto Dia de Pr√°tica - 5-Day AI Agents Intensive Course with Google

- [5-Day AI Agents Intensive Course with Google](https://www.kaggle.com/learn-guide/5-day-agents?utm_medium=email&utm_source=gamma&utm_campaign=learn-aiagents-2025)

 
De forma mais ampla, os tr√™s pilares a serem considerados aqui seriam: 

1. **Implementa√ß√£o de agentes de IA**
2. **Escalabidade das opera√ß√µes de agentes de IA**
3. **Ambientes de produ√ß√£o para opera√ß√µes com agentes**


E, ainda pensando de forma mais geral, alguns dos problemas mais cr√≠ticos √†s opera√ß√µes com agentes de IA seriam:

1. **Os agentes interagem de forma aut√¥noma**
2. **Embora os modelos LLM seja stateless, os agentes de IA precisam guardar sess√£o e mem√≥ria das opera√ß√µes**
3. **Os agentes de IA possuem seguem um caminho de execu√ß√£o n√£o determinista ou din√¢mico**


Assim, para responder aos desafios dispostos acima, a documenta√ß√£o da Google afirma que as opera√ß√µes com agentes de IA precisam:

1. **Ter avalia√ß√£o automatizada**
2. **Ter seu ambiente de desenvolvimento e de implementa√ß√£o automatizado (CI/CD)**
3. **Monitoramento extensivo (i.e. managing both health and risks, etc.)**


![os-diferentes-estagios-do-desenvolvimento-continuo-ci-cd](./public/os-diferentes-estagios-do-desenvolvimento-continuo-ci-cd)


<br>

> [!NOTE]
> Practical Implementation Guide
> Throughout this whitepaper, practical examples reference the **Google Cloud Platform Agent Starter Pack**, a Python package providing production-ready Generative AI agent templates for Google Cloud. It includes pre-built agents, automated CI/CD setup, Terraform deployment, Vertex AI evaluation integration and built-in Google Cloud observability. The starter pack demonstrates the concepts discussed here with working code you can deploy in minutes.
> Prototype to Production (AI Agents) - Katkis, S., Hernandez, G., et altri,  Google, 2025


<br>

Ademais, pensando na aplica√ß√£o de padr√µes e de boas pr√°ticas, ainda poderiamos falar tamb√©m de algumas outras importantes pr√°ticas a serem aplicadas √† produ√ß√£o com agentes de IA:

- **Infraestrutura como C√≥digo (IaC)**: como a da ferramenta **Terraform**, etc.
- **Ferramentas de Testes Automatizadas**: como a biblioteca **Pytest**, etc.
- **Uso de Gerenciadores de Segredos ou de Chaves**: como o servi√ßo **Secret Manager**, etc. 
- **Estrat√©gias Seguras de Rollup (Implanta√ß√£o)**: como as estrat√©gias **Canary**, **Blue-Green**, **A/B Testing**, **Feature Flags**, etc.
- **Performance**: como a constru√ß√µes de agente simples, especializados e trabalhando em paralelo sempre que poss√≠vel.
- **Robustez**: como a capacidade do agente de lidar com erros, novas tentativas, bem como de falhar de forma segura.
- **Custo**: como da prefer√™ncia por economicidade, que seria, por exemplo, de escolher os modelos LLMs mais em conta, embora suficientes para executar com sucesso os requisitos planejados.   
- **Padroniza√ß√£o MCP (Model Context Protocol) e Agent Registry**: para garantir o uso seguro e interoper√°vel dos agentes de IA e das ferramentas.
- **Padroniza√ß√£o A2A (Agent2Agent), Agent Card e Agent Registry**: como, por exemplo, focar na interoperabilidade entre agentes de IA, indepedentemente da ferramenta respons√°vel pela constru√ß√£o de cada um deles.

[AgentOps: Operationalize AI Agents (Youtube)](https://www.youtube.com/watch?v=kJRgj58ujEk)


<br>

J√° abaixo, temos uma breve descri√ß√£o da documenta√ß√£o da Google para se fazer a distin√ß√£o entre as padroniza√ß√µes: **MCP** e **A2A**

> "The distinction is critical. When you need a simple, stateless function like fetching weather data or querying a database, you need a tool that speaks MCP. But when you need to delegate a complex goal, such as "analyze last quarter's customer churn and recommend three intervention strategies," you need an intelligent partner that can reason, plan, and act autonomously via A2A. In short, MCP lets you say, "Do this specific thing," while A2A lets you
say, "Achieve this complex goal."[...] the collaboration is discovering the right agent to delegate to - this is made possible through Agent Cards,24 which are standardized JSON specifications that act as a business card for each agent. An Agent Card describes what an agent can do, its security requirements, its skills, and how to reach out to it (url), allowing any other agent in the ecosystem to dynamically discover its peers."
> Prototype to Production (AI Agents) - Katkis, S., Hernandez, G., et altri - Google - 2025 (p. 27-28)


![descrevendo-o-trabalho-conjunto-dos-padroes-mcp-e-a2a](./public/descrevendo-o-trabalho-conjunto-dos-padroes-mcp-e-a2a.png)


<br>

Assim, aqui temos um exemplo de como se definir um **"Agent Card"** de identificando um agente de IA perante outros agentes:

```
{
    "name": "check_prime_agent",
    "version": "1.0.0",
    "description": "An agent specialized in checking whether numbers are prime",
    "capabilities": {},
    "securitySchemes": {
        "agent_oauth_2_0": {
            "type": "oauth2",
        }
    }
    "defaultInputModes": ["text/plain"],
    "defaultOutputModes": ["application/json"],
    "skills": [
            {"id": "prime_checking",
            "name": "Prime Number Checking",
            "description": "Check if numbers are prime using efficient algorithms",
            "tags": ["mathematical", "computation", "prime"]}
    ],
    "url": "http://localhost:8001/a2a/check_prime_agent"
}
```


De forma geral, o notebook de estudo da primeira pr√°tica deste √∫ltimo dia descreve o problema geral do uso da padroniza√ß√£o **Agent2Agent (A2A)** da seguinte forma:

- **Os agentes de IA precisam se integrar com plataformas externas mantidas por third-parities**
- **A exist√™ncia de diferentes modelos de opera√ß√µes em execu√ß√£o com agentes de IA em diferentes organiza√ß√µes** 
- **A necessidade da exist√™ncia de contratos de servi√ßos formais entre as diferentes plataformas**
- **Os produtos e servi√ßos externos podem estar definidos em diferentes linguagens ou ferramentas** 

![dedindo-pelo-uso-do-protocolo-agent2agent-ou-pelo-uso-de-sub-agents](./public/dedindo-pelo-uso-do-protocolo-agent2agent-ou-pelo-uso-de-sub-agents.png)


<br>

### Pratica 

Como foi discorrido acima, na parte te√≥rica do documento da Google para esta √∫ltima pr√°tica deste √∫ltimo dia de estudo da trilha, o objetivo geral agora √© o de pensar no **Ambiente de Produ√ß√£o**, para podermos trabalhar de forma consistente desde a implementa√ß√£o, passando pela escalabilidade e mantendo de forma robusta a gest√£o do funcionamento da opera√ß√£o em seu ambiente de produ√ß√£o.


Para tanto, nesta primeira pr√°tica o recursos de aprendizado prop√µe como foco trabalhar a implementa√ß√£o do padr√£o **Agent2Agent (A2A)** que √© respons√°vel por definir como deve ser gerenciado a integra√ß√£o externa dos agentes de IA.

![entendendo-o-padrao-da-arquitetura-agent2agent-a2a-dos-agentes-de-ia](./public/entendendo-o-padrao-da-arquitetura-agent2agent-a2a-dos-agentes-de-ia.png)


<br>

Assim, pensando em termos gerais nos requisitos mais importantes a serem considerados no desenvolvimento de uma opera√ß√£o com agentes de IA, o recurso de aprendizado do curso nos lembra que:

- **Agentes de IA simples e especializados**: esse deve ser o modelo prevalente, pois trabalha melhor a escalabilidade.
- **Gest√£o da colabora√ß√£o entre m√∫ltiplo agentes de IA**: esse deve ser do outro lado, o modelo indicado para permitir eslacar as opera√ß√µes.
- **Interoperabilidade**: de forma que diferentes times/opera√ß√µes possam ser integrados em comum. 
- **Padroniza√ß√£o**: um protocolo padronizado de comunica√ß√£o capaz de permitir o uso comum de diferentes linguagens/frameworks.


Descri√ß√£o proposta para o ambiente de produ√ß√£o desta P√°tica I:

![descricao-do-ambiente-de-producao-da-operacao-proposta-pela-operacao-com-agentes-de-ia-pratica-1](./public/descricao-do-ambiente-de-producao-da-operacao-proposta-pela-operacao-com-agentes-de-ia-pratica-1.png)


<br>

Na sequ√™ncia, ent√£o, para podermos colocar em pr√°tica esta √∫ltima grande pr√°tica de uma opera√ß√£o com agentes de IA, temos que fazer, como de costume, preparar o ambiente de opera√ß√£o para os agentes de IA.


Assim, como se tem repetido em todas as pr√°ticas feitas anteriormente, tudo se deve se iniciar pela confer√™ncia do status da instal√ß√£o da biblioteca da biblioteca da Google, o **google-adk**, ela que j√° fora instalada ainda no primeiro dia do curso!

```
pip install -q google-adk[a2a]
``` 


Finalmente, fa√ßa tamb√©m o trabalho de gest√£o da chave de autentica√ß√£o do Google para a conex√£o com a sua Api Gemini. 
```
import os
from kaggle_secrets import UseSecretsClient

try:
    GOOGLE_API_KEY = UserSecretsClient().get_secret("GOOGLE_API_KEY")
    os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY
    print("‚úÖ Setup and authentication complete.")
except:
    print(
        f"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}"
    )
```


<br>

Contudo, para podermos finalizar o trabalho de prepara√ß√£o do ambiente, √© preciso ainda fazer as seguintes configura√ß√µes no ambiente local da opera√ß√£o, novamente envolvendo funcionalidades da biblioteca Google do **google-adk**:

```
import json
import requests
import subprocess
import time
import uuid

from google.adk.agents import LlmAgent
from google.adk.agents.remote_a2a_agent import {
    RemoteA2aAgent,
    AGENT_CARD_WELL_KNOWN_PATH,
} 

from google.adk.utils.agent_to_a2a import to_a2a
from google.adk.models.google_llm import Gemini
from googl.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from goole.genai import types

# Hide additional warning in the notebook
import warnings

warnings.filterwarnings("ignore")

print("‚úÖ ADK components imported successfully.")
```


> [!NOTE]
> Observe que num ambiente real de produ√ß√£o, o c√≥digo acima deveria ser refatorado para separar as responsabilidades da configura√ß√£o do **M√≥dulo de Incializa√ß√£o** da opera√ß√£o e do **root_agente**.
> O m√≥dulo de inicializa√ß√£o, normalmente definido num arquivo **main.py**, **app.py** ou **run.py** seria respons√°vel por inicializar o sistema, gerenciar as chaves de APIs, iniciar o runner e criar os agentes, enquanto que o root_agent teria como responsabilidade a defini√ß√£o de um agente de IA para servir como orquestrador capaz de gerenciar a comunica√ß√£o geral dos demais agentes de IA.


<br>

Finalmente, para terminar toda a configura√ß√£o do ambiente de execu√ß√£o, √© preciso definir e configurar a forma de lidar com os erros dos modelos LLM dos agentes de IA √© executado: 

```
retry_config = types.HttpRetryOptions(
    attempts=5,  # Maximum retry attempts
    exp_base=7,  # Delay multiplier
    initial_delay=1,
    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors
)
```


Assim, depois de devidamente preparado o ambiente local do projeto, podemos iniciar o desenvolvimento da opera√ß√£o que ser√° criada para a opera√ß√£o dos agentes de IA usando a padroniza√ß√£o **Agent2Agent**.


Nesse sentido, o recurso de ensino come√ßa criando um **Agente de IA Respons√°vel por manter um Produto de Cat√°logo de Servi√ßo Externo**, ou seja, trata-se de um agente de IA que n√£o pertence √† nossa organiza√ß√£o e que n√£o √© controlado por ela, mas que **pode ser acessado via A2A para ter as suas informa√ß√µes consumidas** pelos agentes da nossa organiza√ß√£o:

```
# Define a product catalog lookup tool
# In a real system, this would query the vendor's product database
def get_product_info(product_name: str) -> str:
    """Get product information for a given product.

    Args:
        product_name: Name of the product (e.g., "iPhone 15 Pro", "MacBook Pro")

    Returns:
        Product information as a string
    """
    # Mock product catalog - In production, this would query a real database!!!
    product_catalog = {
        "iphone 15 pro": "iPhone 15 Pro, $999, Low Stock (8 units), 128GB, Titanium finish",
        "samsung galaxy s24": "Samsung Galaxy S24, $799, In Stock (31 units), 256GB, Phantom Black",
        "dell xps 15": 'Dell XPS 15, $1,299, In Stock (45 units), 15.6" display, 16GB RAM, 512GB SSD',
        "macbook pro 14": 'MacBook Pro 14", $1,999, In Stock (22 units), M3 Pro chip, 18GB RAM, 512GB SSD',
        "sony wh-1000xm5": "Sony WH-1000XM5 Headphones, $399, In Stock (67 units), Noise-canceling, 30hr battery",
        "ipad air": 'iPad Air, $599, In Stock (28 units), 10.9" display, 64GB',
        "lg ultrawide 34": 'LG UltraWide 34" Monitor, $499, Out of Stock, Expected: Next week',
    }

    product_lower = product_name.lower().strip()

    if product_lower in product_catalog:
        return f"Product: {product_catalog[producgt_lower]}"
    else:
        available = ", ".join([p.title() for p in product_catalog.keys()])
        return f"Sorry, I don't have information for {product_name}. Available products: {available}"

    # Create the Product Catalog Agent
    # This agent specializes in providing product information from the vendor's catalog
    product_catalog_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="product_catalog_agent",
    description="External vendor's product catalog agent that provides product information and availability.",
    instruction="""
    You are a product catalog specialist from an external vendor.
    When asked about products, use the get_product_info tool to fetch data from the catalog.
    Provide clear, accurate product information including price, availability, and specs.
    If asked about multiple products, look up each one.
    Be professional and helpful.
    """,
    tools=[get_product_info], # Register the product lookup tool
)

print("‚úÖ Product Catalog Agent created successfully!")
print("   Model: gemini-2.5-flash-lite")
print("   Tool: get_product_info()")
print("   Ready to be exposed via A2A...")
```


A seguir, √© preciso que aquele agente de IA disponibilizado acima seja devidamente registrado internamente pela organiza√ß√£o em sua pr√≥pria opera√ß√£o com agentes de IA.


Assim, no c√≥digo abaixo temos:

```
# Convert the product catalog agent to an A2A - Compatible application
# This creates a FastAPI/Starlette app that:
# 1. Serves the agent at the A2A protocol endpoints.
# 2. Provides an auto-generated agent card.
# 3. Handles A2A communication protocol.
product_catalog_a2a.app = to_a2a(
   product_catalog_agent, port=8001 # Port where this agent will be served 
)

print("‚úÖ Product Catalog Agent is now A2A-compatible!")
print("   Agent will be served at: http://localhost:8001")
print("   Agent card will be at: http://localhost:8001/.well-known/agent-card.json")
print("   Ready to start the server...")
```

> [!NOTE]
> Novamente, considerando um ambiente de produ√ß√£o real e que deve seguir as boas pr√°ticas, tal exposi√ß√£o dos agentes de IA que podem ser acessados pelos agentes internos deveriam fazer parte, seja de um projeto espec√≠fico voltado para expor esses agentes como se fossem microservi√ßos, seja na forma de um grande esquema de **Registro de Agentes**, para o caso das grandes opera√ß√µes com agentes de IA, onde ter√≠amos um sistema complexo de registro e descoberta de agentes de IA sendo gerenciados.



<br>

Finalmente, para finalizar a simula√ß√£o do servi√ßo externo, temos a cria√ß√£o de um **servidor usando uvicorn** que ser√° respons√°vel por gerir a opera√ß√£o **Cat√°logo de Produtos** que √© disponibilizada externamente por alguma empresa:

```
# First, let's save the product catalog agent to a file that uvicorn can import
import os
from google.adk.agents import LlmAgent
from google.adk.a2a.utils.agent_to_a2a import to_a2a
from google.adk.models.google_llm import Gemini
from google.genai import types

retry_config = types.HttpRetryOptions(
    attempts=5,  # Maximum retry attempts
    exp_base=7,  # Delay multiplier
    initial_delay=1,
    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors
)

def get_product_info(product_name: str) -> str:
    """Get product information for a given product."""
    product_catalog = {
        "iphone 15 pro": "iPhone 15 Pro, $999, Low Stock (8 units), 128GB, Titanium finish",
        "samsung galaxy s24": "Samsung Galaxy S24, $799, In Stock (31 units), 256GB, Phantom Black",
        "dell xps 15": "Dell XPS 15, $1,299, In Stock (45 units), 15.6\\" display, 16GB RAM, 512GB SSD",
        "macbook pro 14": "MacBook Pro 14\\", $1,999, In Stock (22 units), M3 Pro chip, 18GB RAM, 512GB SSD",
        "sony wh-1000xm5": "Sony WH-1000XM5 Headphones, $399, In Stock (67 units), Noise-canceling, 30hr battery",
        "ipad air": "iPad Air, $599, In Stock (28 units), 10.9\\" display, 64GB",
        "lg ultrawide 34": "LG UltraWide 34\\" Monitor, $499, Out of Stock, Expected: Next week",
    }

    product_lower = product_name.lower().strip()

    if product_lower in product_catalog:
        return f"Product: {product_catalog[product_lower]}"
    else:
        available = ", ".join([p.title() for p in product_catalog.key()])
        return f"Sorry, I don't have information for {product_name}. Available products: {available}"

product_catalog_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="product_catalog_agent",
    description="External vendor's product catalog agent that provides product information and availability.",
    instruction="""
    You are a product catalog specialist from an external vendor.
    When asked about products, use the get_product_info tool to fetch data from the catalog.
    Provide clear, accurate product information including price, availability, and specs.
    If asked about multiple products, look up each one.
    Be professional and helpful.
    """,
    tools=[get_product_info]
) 

# Create the A2A app
app = to_a2a(product_catalog_agent, port=8001)

# Write the product catalog agent to a temporary file
with open("/tmp/product_catalog_server.py", "w") as f:
    f.write(product_catalog_agent_code)

print("üìù Product Catalog agent code saved to /tmp/product_catalog_server.py")

# Start uvicorn server in background
# Note: We redirect output to avoid cluttering the notebook
server_process = subprocess.Popen(
    [
        "uvicorn",
        "product_catalog_server:app", # Module:app format
        "--host",
        "localhost",
        "--port",
        "8001",
    ],
    cwd="/tmp", # Run from /tmp where the file is
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
    env=(**os.environ), # Pass environment variables (including GOOGLE_API_KEY)
)

print("üöÄ Starting Product Catalog Agent server...")
print("   Waiting for server to be ready...")

# Wait for server to start (poll until it responds)
max_attemps = 30
for attempt in range(max_attempts):
    try:
        response = request.get(
            "http://localhost:8001/.well-known/agent-card.json", timeout=1
        )
        if response.status_code == 200:
            print(f"\n‚úÖ Product Catalog Agent server is running!")
            print(f"   Server URL: http://localhost:8001")
            print(f"   Agent card: http://localhost:8001/.well-known/agent-card.json")
            break
    except:
        print("\n‚ö†Ô∏è  Server may not be ready yet. Check manually if needed.")

# Store the process so we can stop it later
globals()["product_catalog_server_process"] = server_process
```


Agora, ent√£o, estaremos criando o **agente de IA** da nossa opera√ß√£o que estar√° consumindo as informa√ß√µes disponibilizadas pelo agente de IA que est√° simulando uma opera√ß√£o mantida por alguma outra organiza√ß√£o externamente.


Mas primeiramente, veja que tamb√©m √© preciso criar deste lado interno da opera√ß√£o uma camada para destacar o uso dos agentes de IA, que no caso funcionaria como que um **servidor proxy** para a opera√ß√£o do agente de IA, propriamente dito que vir√° logo na sequ√™ncia:

```
#Create a RemoteA2Agent that connects to our Product Catalog Agent
# This acts as a client-side proxy - the Customer Support Agent can use it like a local agent
remote_product_catalog_agent = RemoteA2aAgent(
    name="product_catalog_agent",
    description="Remote product catalog agent from external vendor that provides product information.",
    # Point to the agent card URL - this is where the A2A protocol metadata lives
    agent_card=f"http://localhost:8001{AGENT_CARD_WELL_KNOWN_PATH}",
)

print("‚úÖ Remote Product Catalog Agent proxy created!")
print(f"   Connected to: http://localhost:8001")
print(f"   Agent card: http://localhost:8001{AGENT_CARD_WELL_KNOWN_PATH}")
print("   The Customer Support Agent can now use this like a local sub-agent!")
``` 


E, agora, criando o agente de IA interno para ser cliente da opera√ß√£o:

```
# Now create the Customer Support Agent that uses the remote Product Catalog Agent
customer_support_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="customer_support_agent",
    description="A customer support assistant that helps customers with product inquiries and information.",
    instruction="""
    You are a friendly and professional customer support agent.
    
    When customers ask about products:
    1. Use the product_catalog_agent sub-agent to look up product information
    2. Provide clear answers about pricing, availability, and specifications
    3. If a product is out of stock, mention the expected availability
    4. Be helpful and professional!
    
    Always get product information from the product_catalog_agent before answering customer questions.
    """,
    sub_agents=[remote_product_catalog_agent],  # Add the remote agent as a sub-agent!
)

print("‚úÖ Customer Support Agent created!")
print("   Model: gemini-2.5-flash-lite")
print("   Sub-agents: 1 (remote Product Catalog Agent via A2A)")
print("   Ready to help customers!")
```

Resumindo o caminho da opera√ß√£o montada, temos:

1. **O cliente pede suporte ao Agente de IA interno de suporte sobre um produto**
2. **O agente interno de IA de suporte recebe o pedido do usu√°rio**
3. **O agente interno de IA de suporte chama/usa o agente de IA proxy (RemoteA2aAgent)**
4. **ADK chama o protocolo A2A chamando a path http://localhost:8001**
5. **O servi√ßo externo de Cat√°logo de Produtos vai processar a requisi√ß√£o e responder de volta ao final**
    5.1. Servidor uvicorn chama o agente externo respons√°vel pelo Cat√°logo de Produtos
    5.2. Agente externo responde ao servidor uvicorn
    5.3. Servidor uvicorn retorna a resposta final
6. **O RemoteA2aAgent recebe a resposta retornada externamente e repassa para o agente de IA interno de suporte**
7. **O agente interno de IA de suporte recebe a resposta e d√° continuidade**
8. **O usu√°rio recebe do agente interno de IA de suporte a resposta final da opera√ß√£o** 


Finalmente, temos o c√≥digo de teste para o ambiente que simula uma opera√ß√£o de produ√ß√£o com um agente de IA fazendo uma consulta externa, usando o protocolo **Agent2Agent**:

```
async def test_a2a_communication(user_query: str):
    """
    Test the A2A communication between Customer Support Agent and Product Catalog Agent.

    This function:
    1. Creates a new session for this conversation
    2. Sends the query to the Customer Support Agent
    3. Support Agent communicates with Product Catalog Agent via A2A
    4. Displays the response

    Args:
        user_query: The question to ask the Customer Support Agent
    """
    # Setup session management (required by ADK)
    session_service = InMemorySessionService()

    # Session identifiers
    app_name = "support_app"
    user_id = "demo_user"
    # Use unique session ID for each test to avoid conflicts
    session_id = f"demo_session_{uuid.uuid4().hex[:8]}"

    # CRITICAL: Create session BEFORE running agent (synchronous, not async!)
    # This pattern matches the deployment notebook exactly
    session = await session_service.create_session(
        app_name=app_name, user_id=user_id, session_id=session_id
    )

    # Create runner for the Customer Support Agent
    # The runner manages the agent execution and session state
    runner = Runner(
        agent=customer_support_agent, app_name=app_name, session_service=session_service
    )

    # Create the user message
    # This follows the same pattern as the deployment notebook
    test_content = types.Content(parts=[types.Part(text=user_query)])

    # Display query
    print(f"\nüë§ Customer: {user_query}")
    print(f"\nüéß Support Agent response:")
    print("-" * 60)

    # Run the agent asynchronously (handles streaming responses and A2A communication)
    async for event in runner.run_async(
        user_id=user_id, session_id=session_id, new_message=test_content
    ):
        # Print final response only (skip intermediate events)
        if event.is_final_response() and event.content:
            for part in event.content.parts:
                if hasattr(part, "text"):
                    print(part.text)

    print("-" * 60)


# Run the test
print("üß™ Testing A2A Communication...\n")
await
 test_a2a_communication("Can you tell me about the iPhone 15 Pro? Is it in stock?") 
```


<br>

## Outros links:

 - [linkedin:] https://www.linkedin.com/in/marcus-vinicius-richa-183104199/
 - [Github:] https://github.com/ahoymarcus/
 - [My Old Web Portfolio:] https://redux-reactjs-personal-portfolio-webpage-version-2.netlify.app/







